{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bc7bd67",
   "metadata": {},
   "source": [
    "# <a href=\"https://colab.research.google.com/github/oftx/python-sstv/blob/main/SSTV_Video_Gen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "# SSTV Video Glitch Generator\n",
    "\n",
    "This notebook runs the `python-sstv` tool suite to convert video to SSTV signal and decode it back, apply random glitch effects (Noise, Jitter, Skew), and simulated analog artifacts.\n",
    "\n",
    "### Features\n",
    "- **Video to SSTV**: Convert MP4 video to SSTV audio and back to frames.\n",
    "- **Glitch Effects**: Phase Jitter (Shake), Clock Drift (Slant/Wobble), Line Tearing.\n",
    "- **Customizable**: Adjust bitrate, resolution presets, and randomness seeds.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 1. Install Dependencies\n",
    "!pip install opencv-python-headless scipy numpy pillow tqdm\n",
    "!apt-get install ffmpeg\n",
    "\n",
    "import os\n",
    "import sys\n",
    "print(\"Dependencies installed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Deploy Code\n",
    "Writing project files to Colab environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile common.py\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Robot36 Constants (Base frequencies)\n",
    "SAMPLE_RATE = 48000\n",
    "\n",
    "# Frequencies\n",
    "SYNC_FREQ = 1200.0\n",
    "PORCH_FREQ = 1500.0\n",
    "VIS_BIT_1_FREQ = 1100.0\n",
    "VIS_BIT_0_FREQ = 1300.0\n",
    "BLACK_FREQ = 1500.0\n",
    "WHITE_FREQ = 2300.0\n",
    "EVEN_SEPARATOR_FREQ = 1500.0\n",
    "ODD_SEPARATOR_FREQ = 2300.0\n",
    "PORCH_SEPARATOR_FREQ = 1900.0\n",
    "LEADER_TONE_FREQ = 1900.0\n",
    "BREAK_FREQ = 1200.0\n",
    "\n",
    "# Base Durations (ms) for Robot36 Standard (320x240)\n",
    "SYNC_DURATION_MS = 9.0\n",
    "SYNC_PORCH_DURATION_MS = 3.0\n",
    "SEPARATOR_DURATION_MS = 4.5\n",
    "PORCH_DURATION_MS = 1.5\n",
    "LEADER_TONE_DURATION_MS = 300.0\n",
    "BREAK_DURATION_MS = 10.0\n",
    "VIS_BIT_DURATION_MS = 30.0\n",
    "\n",
    "def ms_to_samples(ms, sample_rate=SAMPLE_RATE):\n",
    "    return int(round(ms * sample_rate / 1000.0))\n",
    "\n",
    "class ModeConfig:\n",
    "    def __init__(self, width=320, height=240, sample_rate=SAMPLE_RATE):\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.sample_rate = sample_rate\n",
    "        \n",
    "        # Calculate scan durations based on width\n",
    "        # Standard Robot36 (320px) takes 88ms for Y and 44ms for UV\n",
    "        # We scale this linearly\n",
    "        self.y_scan_duration_ms = 88.0 * (width / 320.0)\n",
    "        self.uv_scan_duration_ms = 44.0 * (width / 320.0)\n",
    "        \n",
    "        # Sample counts\n",
    "        self.sync_samples = ms_to_samples(SYNC_DURATION_MS, sample_rate)\n",
    "        self.sync_porch_samples = ms_to_samples(SYNC_PORCH_DURATION_MS, sample_rate)\n",
    "        self.separator_samples = ms_to_samples(SEPARATOR_DURATION_MS, sample_rate)\n",
    "        self.porch_samples = ms_to_samples(PORCH_DURATION_MS, sample_rate)\n",
    "        \n",
    "        self.y_scan_samples = ms_to_samples(self.y_scan_duration_ms, sample_rate)\n",
    "        self.uv_scan_samples = ms_to_samples(self.uv_scan_duration_ms, sample_rate)\n",
    "\n",
    "        # Header samples (fixed)\n",
    "        self.leader_tone_samples = ms_to_samples(LEADER_TONE_DURATION_MS, sample_rate)\n",
    "        self.break_samples = ms_to_samples(BREAK_DURATION_MS, sample_rate)\n",
    "        self.vis_bit_samples = ms_to_samples(VIS_BIT_DURATION_MS, sample_rate)\n",
    "\n",
    "def get_mode_config(width, height, sample_rate=SAMPLE_RATE):\n",
    "    return ModeConfig(width, height, sample_rate)\n",
    "\n",
    "def rgb_to_yuv(r, g, b):\n",
    "    # Rec. 601 limited range as per Java implementation\n",
    "    # Y = 16 + (65.738*R + 129.057*G + 25.064*B) / 256\n",
    "    # U = 128 + (-37.945*R - 74.494*G + 112.439*B) / 256\n",
    "    # V = 128 + (112.439*R - 94.154*G - 18.285*B) / 256\n",
    "    \n",
    "    y = 16.0 + (65.738 * r + 129.057 * g + 25.064 * b) / 256.0\n",
    "    u = 128.0 + (-37.945 * r - 74.494 * g + 112.439 * b) / 256.0\n",
    "    v = 128.0 + (112.439 * r - 94.154 * g - 18.285 * b) / 256.0\n",
    "    \n",
    "    return np.clip(y, 16, 235), np.clip(u, 16, 240), np.clip(v, 16, 240)\n",
    "\n",
    "def yuv_to_rgb(y, u, v):\n",
    "    # Inverse of the above\n",
    "    # Y -= 16\n",
    "    # U -= 128\n",
    "    # V -= 128\n",
    "    # R = (298 * Y + 409 * V + 128) >> 8\n",
    "    # G = (298 * Y - 100 * U - 208 * V + 128) >> 8\n",
    "    # B = (298 * Y + 516 * U + 128) >> 8\n",
    "    \n",
    "    y_shifted = y - 16.0\n",
    "    u_shifted = u - 128.0\n",
    "    v_shifted = v - 128.0\n",
    "    \n",
    "    r = (298.082 * y_shifted + 408.583 * v_shifted) / 256.0\n",
    "    g = (298.082 * y_shifted - 100.291 * u_shifted - 208.120 * v_shifted) / 256.0\n",
    "    b = (298.082 * y_shifted + 516.412 * u_shifted) / 256.0\n",
    "    \n",
    "    return np.clip(r, 0, 255), np.clip(g, 0, 255), np.clip(b, 0, 255)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile encoder.py\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import argparse\n",
    "from PIL import Image\n",
    "from scipy.io import wavfile\n",
    "import common\n",
    "\n",
    "class SSTVEncoder:\n",
    "    def __init__(self, image_source, width=320, height=240, sample_rate=common.SAMPLE_RATE):\n",
    "        self.image_source = image_source\n",
    "        self.config = common.get_mode_config(width, height, sample_rate)\n",
    "        self.phase = 0.0\n",
    "        self.audio_buffer = []\n",
    "\n",
    "    def load_and_process_image(self):\n",
    "        if isinstance(self.image_source, str):\n",
    "            img = Image.open(self.image_source).convert('RGB')\n",
    "        elif isinstance(self.image_source, Image.Image):\n",
    "            img = self.image_source.convert('RGB')\n",
    "        elif isinstance(self.image_source, np.ndarray):\n",
    "            img = Image.fromarray(self.image_source).convert('RGB')\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported image source type\")\n",
    "            \n",
    "        img = img.resize((self.config.width, self.config.height), Image.Resampling.LANCZOS)\n",
    "        return np.array(img)\n",
    "\n",
    "    def add_tone(self, freq, duration_samples):\n",
    "        # Generate tone with continuous phase\n",
    "        t = np.arange(duration_samples)\n",
    "        phase_increment = 2 * np.pi * freq / self.config.sample_rate\n",
    "        phases = self.phase + phase_increment * t\n",
    "        \n",
    "        # Update phase for next segment\n",
    "        self.phase = phases[-1] + phase_increment \n",
    "        \n",
    "        tone = np.sin(phases)\n",
    "        self.audio_buffer.append(tone)\n",
    "\n",
    "    def add_scan_line_tone(self, pixels, duration_samples, channel_idx):\n",
    "        # pixels: array of pixel values for the channel\n",
    "        # Map pixel values to frequency range 1500Hz - 2300Hz\n",
    "        \n",
    "        freqs = common.BLACK_FREQ + (pixels * (common.WHITE_FREQ - common.BLACK_FREQ) / 255.0)\n",
    "        \n",
    "        # Generate samples with varying frequency (FM)\n",
    "        t_indices = np.linspace(0, len(pixels) - 1, duration_samples)\n",
    "        interpolated_freqs = np.interp(t_indices, np.arange(len(pixels)), freqs)\n",
    "        \n",
    "        # Integrate frequency to get phase\n",
    "        # phase[n] = phase[n-1] + 2*pi*f[n]/Fs\n",
    "        phase_increments = 2 * np.pi * interpolated_freqs / self.config.sample_rate\n",
    "        cumulative_phases = np.cumsum(phase_increments) + self.phase\n",
    "        \n",
    "        self.phase = cumulative_phases[-1]\n",
    "        \n",
    "        tone = np.sin(cumulative_phases)\n",
    "        self.audio_buffer.append(tone)\n",
    "\n",
    "    def generate_header(self):\n",
    "        # Calibration Header\n",
    "        # Leader tone\n",
    "        self.add_tone(common.LEADER_TONE_FREQ, self.config.leader_tone_samples)\n",
    "        # Break\n",
    "        self.add_tone(common.BREAK_FREQ, self.config.break_samples)\n",
    "        # Leader tone\n",
    "        self.add_tone(common.LEADER_TONE_FREQ, self.config.leader_tone_samples)\n",
    "        # VIS Start bit\n",
    "        self.add_tone(common.BREAK_FREQ, self.config.vis_bit_samples)\n",
    "        \n",
    "        # VIS Code 8 (Robot36): 00001000 (LSB first) -> 0, 0, 0, 1, 0, 0, 0, 0\n",
    "        vis_code = 8\n",
    "        parity = 0\n",
    "        for i in range(7):\n",
    "            bit = (vis_code >> i) & 1\n",
    "            parity ^= bit\n",
    "            freq = common.VIS_BIT_1_FREQ if bit else common.VIS_BIT_0_FREQ\n",
    "            self.add_tone(freq, self.config.vis_bit_samples)\n",
    "            \n",
    "        # Parity bit\n",
    "        freq = common.VIS_BIT_1_FREQ if parity else common.VIS_BIT_0_FREQ\n",
    "        self.add_tone(freq, self.config.vis_bit_samples)\n",
    "        \n",
    "        # Stop bit\n",
    "        self.add_tone(common.BREAK_FREQ, self.config.vis_bit_samples)\n",
    "\n",
    "    def write_wav(self, file_object):\n",
    "        img_array = self.load_and_process_image()\n",
    "        \n",
    "        # Convert to YUV\n",
    "        r = img_array[:,:,0].astype(float)\n",
    "        g = img_array[:,:,1].astype(float)\n",
    "        b = img_array[:,:,2].astype(float)\n",
    "        \n",
    "        y, u, v = common.rgb_to_yuv(r, g, b)\n",
    "        \n",
    "        # Generate Audio\n",
    "        self.generate_header()\n",
    "        \n",
    "        for line in range(self.config.height):\n",
    "            # Sync\n",
    "            self.add_tone(common.SYNC_FREQ, self.config.sync_samples)\n",
    "            # Sync Porch\n",
    "            self.add_tone(common.PORCH_FREQ, self.config.sync_porch_samples)\n",
    "            \n",
    "            # Y Scan\n",
    "            self.add_scan_line_tone(y[line], self.config.y_scan_samples, 0)\n",
    "            \n",
    "            if line % 2 == 0:\n",
    "                # Even Line: Separator (1500) -> Porch -> V Scan\n",
    "                self.add_tone(common.EVEN_SEPARATOR_FREQ, self.config.separator_samples)\n",
    "                self.add_tone(common.PORCH_SEPARATOR_FREQ, self.config.porch_samples)\n",
    "                self.add_scan_line_tone(v[line], self.config.uv_scan_samples, 2)\n",
    "            else:\n",
    "                # Odd Line: Separator (2300) -> Porch -> U Scan\n",
    "                self.add_tone(common.ODD_SEPARATOR_FREQ, self.config.separator_samples)\n",
    "                self.add_tone(common.PORCH_SEPARATOR_FREQ, self.config.porch_samples)\n",
    "                self.add_scan_line_tone(u[line], self.config.uv_scan_samples, 1)\n",
    "\n",
    "        # Concatenate and save\n",
    "        full_signal = np.concatenate(self.audio_buffer)\n",
    "        \n",
    "        # Normalize to 16-bit PCM range\n",
    "        # full_signal is -1.0 to 1.0\n",
    "        audio_data = (full_signal * 32767).astype(np.int16)\n",
    "        \n",
    "        wavfile.write(file_object, self.config.sample_rate, audio_data)\n",
    "\n",
    "    def encode(self, output_path):\n",
    "        with open(output_path, 'wb') as f:\n",
    "            self.write_wav(f)\n",
    "        print(f\"SSTV Audio saved to {output_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(description=\"Python Robot36 SSTV Encoder\")\n",
    "    parser.add_argument(\"input_image\", help=\"Path to input image\")\n",
    "    parser.add_argument(\"output_wav\", help=\"Path to output WAV file\")\n",
    "    parser.add_argument(\"--width\", type=int, default=320, help=\"Output width (default: 320)\")\n",
    "    parser.add_argument(\"--height\", type=int, default=240, help=\"Output height (default: 240)\")\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    encoder = SSTVEncoder(args.input_image, args.width, args.height)\n",
    "    encoder.encode(args.output_wav)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile decoder.py\n",
    "\n",
    "import numpy as np\n",
    "import scipy.signal as signal\n",
    "from scipy.io import wavfile\n",
    "from PIL import Image\n",
    "import common\n",
    "import sys\n",
    "import argparse\n",
    "import subprocess\n",
    "import os\n",
    "import tempfile\n",
    "\n",
    "class SSTVDecoder:\n",
    "    def __init__(self, audio_source, width=320, height=240, force_device=None, verbose=True, sample_rate_skew=0.0):\n",
    "        self.verbose = verbose\n",
    "        self.audio_source = audio_source\n",
    "        self._load_audio(audio_source)\n",
    "        \n",
    "        # Apply Clock Skew (Simulate wow/flutter/playback speed error)\n",
    "        if sample_rate_skew != 0.0:\n",
    "            if self.verbose: print(f\"Applying Clock Skew: {sample_rate_skew*100:.4f}%\")\n",
    "            self.sample_rate = int(self.sample_rate * (1.0 + sample_rate_skew))\n",
    "             \n",
    "        self.freqs = None\n",
    "        self.config = common.get_mode_config(width, height, self.sample_rate)\n",
    "        \n",
    "        # Device Selection for Acceleration\n",
    "        self.device = self._select_device(force_device)\n",
    "\n",
    "    def _select_device(self, force=None):\n",
    "        if force == 'cpu':\n",
    "            if self.verbose: print(\"Using Device: CPU (Forced)\")\n",
    "            return None # None triggers CPU fallback block\n",
    "            \n",
    "        try:\n",
    "            import torch\n",
    "            if force == 'cuda' and torch.cuda.is_available():\n",
    "                 return torch.device(\"cuda\")\n",
    "            if force == 'mps' and torch.backends.mps.is_available():\n",
    "                 return torch.device(\"mps\")\n",
    "                 \n",
    "            if torch.cuda.is_available():\n",
    "                if self.verbose: print(\"Using Device: CUDA (NVIDIA)\")\n",
    "                return torch.device(\"cuda\")\n",
    "            elif torch.backends.mps.is_available():\n",
    "                if self.verbose: print(\"Using Device: MPS (Apple Silicon)\")\n",
    "                return torch.device(\"mps\")\n",
    "            else:\n",
    "                if self.verbose: print(\"Using Device: CPU (PyTorch)\")\n",
    "                return torch.device(\"cpu\")\n",
    "        except ImportError:\n",
    "            if self.verbose: print(\"Using Device: CPU (NumPy/SciPy) - PyTorch not found\")\n",
    "            return None\n",
    "\n",
    "\n",
    "    def _load_audio(self, source):\n",
    "        # Try to read as standard WAV first\n",
    "        try:\n",
    "            # wavfile.read accepts file path or file-like object\n",
    "            self.sample_rate, self.audio_data = wavfile.read(source)\n",
    "        except ValueError:\n",
    "            # If source is a string (path), we can try to convert\n",
    "            if isinstance(source, str):\n",
    "                if self.verbose: print(f\"File {source} is not a standard WAV. Trying to convert via ffmpeg...\")\n",
    "                self._convert_and_load(source)\n",
    "            else:\n",
    "                # If it's a file-like object and failed wav read, we can't easily ffmpeg it without writing to disk\n",
    "                # For now assume file-like objects must be valid WAVs if passed directly\n",
    "                raise ValueError(\"Provided audio source is not a valid WAV file and cannot be auto-converted.\")\n",
    "        \n",
    "        if self.audio_data.ndim > 1:\n",
    "            self.audio_data = self.audio_data[:, 0] # Take first channel if stereo\n",
    "        \n",
    "        # Normalize\n",
    "        if self.audio_data.dtype == np.int16:\n",
    "            self.audio_data = self.audio_data / 32768.0\n",
    "        elif self.audio_data.dtype == np.int32:\n",
    "             self.audio_data = self.audio_data / 2147483648.0\n",
    "        elif self.audio_data.dtype == np.uint8:\n",
    "             self.audio_data = (self.audio_data - 128) / 128.0\n",
    "\n",
    "    def _convert_and_load(self, path):\n",
    "        # Use ffmpeg to convert to temporary wav file\n",
    "        # wavfile.read requires a file on disk (or strictly formatted bytes), \n",
    "        # easiest is to dump to temp file\n",
    "        \n",
    "        with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as tf:\n",
    "            temp_name = tf.name\n",
    "            \n",
    "        try:\n",
    "            # Convert to 48kHz mono 16-bit PCM wav\n",
    "            cmd = [\n",
    "                'ffmpeg', '-y', '-i', path, \n",
    "                '-ar', '48000', '-ac', '1', \n",
    "                '-f', 'wav', temp_name\n",
    "            ]\n",
    "            subprocess.run(cmd, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "            self.sample_rate, self.audio_data = wavfile.read(temp_name)\n",
    "        except subprocess.CalledProcessError:\n",
    "            print(\"Error: ffmpeg conversion failed or ffmpeg not installed.\")\n",
    "            sys.exit(1)\n",
    "        finally:\n",
    "            if os.path.exists(temp_name):\n",
    "                os.remove(temp_name)\n",
    "        \n",
    "    def _hilbert_torch(self, x):\n",
    "        import torch\n",
    "        # Hilbert transform via FFT\n",
    "        # MPS often has issues with arbitrary sizes in older PyTorch versions.\n",
    "        # Padding to next power of 2 helps stability and performance.\n",
    "        n_orig = x.shape[-1]\n",
    "        n_pad = 2**(n_orig - 1).bit_length()\n",
    "        \n",
    "        # 1. FFT (with padding)\n",
    "        # clone() is needed to ensure memory is contiguous which MPS likes\n",
    "        Xf = torch.fft.fft(x, n=n_pad)\n",
    "        \n",
    "        # 2. Create heavy-side function in freq domain\n",
    "        h = torch.zeros(n_pad, device=x.device)\n",
    "        if n_pad % 2 == 0:\n",
    "            h[0] = h[n_pad // 2] = 1\n",
    "            h[1:n_pad // 2] = 2\n",
    "        else:\n",
    "            h[0] = 1\n",
    "            h[1:(n_pad + 1) // 2] = 2\n",
    "            \n",
    "        # 3. Multiply and IFFT\n",
    "        # We need to truncate back to original length\n",
    "        return torch.fft.ifft(Xf * h)[..., :n_orig]\n",
    "\n",
    "    def demodulate(self):\n",
    "        if self.verbose: print(\"Demodulating audio...\")\n",
    "        \n",
    "        if self.device is not None:\n",
    "             # GPU / PyTorch Acceleration\n",
    "             import torch\n",
    "             try:\n",
    "                 if self.verbose: print(f\"Accelerating demodulation on {self.device}...\")\n",
    "                 # Move data to GPU\n",
    "                 # Ensure float32 for GPU efficiency (audio usually normalized -1..1)\n",
    "                 audio_tensor = torch.from_numpy(self.audio_data.astype(np.float32)).to(self.device)\n",
    "                 \n",
    "                 # 1. Hilbert\n",
    "                 # PyTorch < 2.0 MPS backend crashes on FFT. 2.0+ supports it.\n",
    "                 use_cpu_fft = False\n",
    "                 if self.device.type == 'mps':\n",
    "                     import re\n",
    "                     # Simple version parsing\n",
    "                     v_str = torch.__version__.split('+')[0]\n",
    "                     major = int(v_str.split('.')[0])\n",
    "                     if major < 2:\n",
    "                         use_cpu_fft = True\n",
    "                 \n",
    "                 if use_cpu_fft:\n",
    "                     # Move to CPU for FFT\n",
    "                     analytic_signal = self._hilbert_torch(audio_tensor.cpu()).to(self.device)\n",
    "                 else:\n",
    "                     # CUDA or Newer MPS handles FFT fine\n",
    "                     analytic_signal = self._hilbert_torch(audio_tensor)\n",
    "                 \n",
    "                 # 2. Phase\n",
    "                 instantaneous_phase = torch.angle(analytic_signal)\n",
    "                 \n",
    "                 # 3. Frequency = diff(unwrapped_phase)\n",
    "                 # Since 'torch.unwrap' is not available in older versions, we calculate distinct phase diffs directly.\n",
    "                 # diff(unwrap(phi)) is equivalent to (diff(phi) + pi) % (2*pi) - pi\n",
    "                 \n",
    "                 diff_phase = torch.diff(instantaneous_phase)\n",
    "                 # Wrap differences to range [-pi, pi]\n",
    "                 diff_phase = (diff_phase + np.pi) % (2 * np.pi) - np.pi\n",
    "                 \n",
    "                 freqs_gpu = (diff_phase / (2.0 * np.pi) * self.sample_rate)\n",
    "                 \n",
    "                 # Move back to CPU for filtering\n",
    "                 # Concatenate 0 pad like original logic\n",
    "                 freqs_np = freqs_gpu.cpu().numpy()\n",
    "                 self.freqs = np.concatenate(([0], freqs_np))\n",
    "                 \n",
    "             except Exception as e:\n",
    "                 print(f\"GPU Acceleration failed: {e}. Falling back to CPU.\")\n",
    "                 self.device = None # Fallback for this run\n",
    "                 \n",
    "        if self.device is None:\n",
    "            # CPU Fallback (Original SciPy Logic)\n",
    "            analytic_signal = signal.hilbert(self.audio_data)\n",
    "            instantaneous_phase = np.unwrap(np.angle(analytic_signal))\n",
    "            # f = (1/2pi) * d(phi)/dt\n",
    "            self.freqs = (np.diff(instantaneous_phase) / (2.0*np.pi) * self.sample_rate)\n",
    "            # Pad one sample to match length\n",
    "            self.freqs = np.concatenate(([0], self.freqs))\n",
    "        \n",
    "        # Low pass filter using SciPy (CPU)\n",
    "        # Maintaining CPU filtering ensures exact signal characteristics and stability\n",
    "        sos = signal.butter(4, 500, 'low', fs=self.sample_rate, output='sos')\n",
    "        self.freqs = signal.sosfiltfilt(sos, self.freqs)\n",
    "\n",
    "    def find_sync_pulses(self):\n",
    "        print(\"Searching for sync pulses...\")\n",
    "        # Robot36 sync is 1200Hz for 9ms\n",
    "        # Thresholds\n",
    "        freq_min = 1100\n",
    "        freq_max = 1300\n",
    "        min_duration_samples = common.ms_to_samples(common.SYNC_DURATION_MS * 0.8, self.sample_rate)\n",
    "        \n",
    "        is_sync = (self.freqs > freq_min) & (self.freqs < freq_max)\n",
    "        \n",
    "        # Find continuous regions\n",
    "        # diff of boolean gives edges\n",
    "        edges = np.diff(is_sync.astype(int))\n",
    "        starts = np.where(edges == 1)[0]\n",
    "        ends = np.where(edges == -1)[0]\n",
    "        \n",
    "        # Handle edge cases\n",
    "        if len(starts) == 0 or len(ends) == 0:\n",
    "            return []\n",
    "            \n",
    "        if ends[0] < starts[0]:\n",
    "            ends = ends[1:]\n",
    "        \n",
    "        if len(starts) > len(ends):\n",
    "            starts = starts[:len(ends)]\n",
    "            \n",
    "        pulses = []\n",
    "        for s, e in zip(starts, ends):\n",
    "            duration = e - s\n",
    "            if duration >= min_duration_samples:\n",
    "                # Store the END of the sync pulse (start of the line)\n",
    "                pulses.append(e)\n",
    "                \n",
    "        return pulses\n",
    "\n",
    "    def decode(self, output_path, shift=0):\n",
    "        self.demodulate()\n",
    "        # Flywheel-Based Decoding (Robust to Missed Syncs)\n",
    "        # 1. Find the first valid sync pulse to bootstrap\n",
    "        bootstrap_syncs = self.find_sync_pulses()\n",
    "        if not bootstrap_syncs:\n",
    "            print(\"No sync pulses found. Cannot decode.\")\n",
    "            return\n",
    "\n",
    "        # Calculate samples per line based on total duration of all components\n",
    "        samples_per_line = (self.config.sync_samples + self.config.sync_porch_samples +\n",
    "                            self.config.y_scan_samples + self.config.separator_samples +\n",
    "                            self.config.porch_samples + self.config.uv_scan_samples)\n",
    "\n",
    "        # Smart Bootstrap: Find the first sync that is part of a periodic chain\n",
    "        # to avoid locking onto the VIS header.\n",
    "        start_sync_index = 0\n",
    "        tolerance = int(samples_per_line * 0.05)\n",
    "        \n",
    "        found_chain = False\n",
    "        for i, candidate in enumerate(bootstrap_syncs):\n",
    "            # Check for a sync pulse at candidate + samples_per_line\n",
    "            target = candidate + samples_per_line\n",
    "            \n",
    "            # Simple check: is there any sync pulse close to target?\n",
    "            # Optimization: could use binary search or efficiently scan, but list is small.\n",
    "            has_next = False\n",
    "            for s in bootstrap_syncs[i+1:]:\n",
    "                if abs(s - target) < tolerance:\n",
    "                    has_next = True\n",
    "                    break\n",
    "                if s > target + tolerance:\n",
    "                    break\n",
    "            \n",
    "            if has_next:\n",
    "                start_sync_index = i\n",
    "                found_chain = True\n",
    "                print(f\"Smart Bootstrap: Locked onto sync chain at index {i} (Sample {candidate})\")\n",
    "                break\n",
    "        \n",
    "        if not found_chain:\n",
    "            print(\"Smart Bootstrap: No chain found, using first sync.\")\n",
    "\n",
    "        current_sample_pos = bootstrap_syncs[start_sync_index]\n",
    "        \n",
    "        # Format shift output for logging\n",
    "        shift_str = str(shift)\n",
    "        if isinstance(shift, (list, np.ndarray)):\n",
    "            if len(shift) > 5:\n",
    "                min_s = np.min(shift)\n",
    "                max_s = np.max(shift)\n",
    "                mean_s = np.mean(shift)\n",
    "                shift_str = f\"[Random Array len={len(shift)}, Min={min_s}, Max={max_s}, Mean={mean_s:.1f}]\"\n",
    "        \n",
    "        print(f\"Starting decode at sample {current_sample_pos} (Shift: {shift_str})\")\n",
    "        \n",
    "        # Buffers\n",
    "        y_image = np.zeros((self.config.height, self.config.width))\n",
    "        u_image = np.full((self.config.height, self.config.width), 128.0)\n",
    "        v_image = np.full((self.config.height, self.config.width), 128.0)\n",
    "        \n",
    "        # Offsets\n",
    "        porch_samples = self.config.sync_porch_samples\n",
    "        y_start = porch_samples\n",
    "        y_end = y_start + self.config.y_scan_samples\n",
    "        \n",
    "        sep_start = y_end\n",
    "        sep_samples = self.config.separator_samples\n",
    "        \n",
    "        porch2_start = sep_start + sep_samples\n",
    "        porch2_samples = self.config.porch_samples\n",
    "        \n",
    "        uv_start = porch2_start + porch2_samples\n",
    "        uv_end = uv_start + self.config.uv_scan_samples\n",
    "        \n",
    "        # State\n",
    "        last_u = np.full(self.config.width, 128.0)\n",
    "        last_v = np.full(self.config.width, 128.0)\n",
    "        \n",
    "        # Search window for re-sync (e.g. +/- 5% of line width)\n",
    "        search_window = int(samples_per_line * 0.05)\n",
    "        \n",
    "        # Thresholds for re-sync search\n",
    "        freq_min = 1100\n",
    "        freq_max = 1300\n",
    "        min_sync_len = common.ms_to_samples(common.SYNC_DURATION_MS * 0.5, self.sample_rate)\n",
    "\n",
    "        # Color Phase State\n",
    "        # Robot36 starts with Line 0 (Even)\n",
    "        # But if we missed lines at start, we might be on Odd.\n",
    "        # We start in \"Unknown\" state? Or just weak lock.\n",
    "        current_phase_is_odd = False \n",
    "        # Start with high mismatch counter to force immediate phase check/flip if signal disagrees\n",
    "        phase_mismatch_counter = 3 \n",
    "        \n",
    "        # Tune Phase Correction\n",
    "        # We only flip phase if we see strong evidence CONTRARY to current state\n",
    "        # to avoid noise flipping it.\n",
    "        \n",
    "        for line_idx in range(self.config.height):\n",
    "            # 1. Try to re-sync (Find \"Sync End\" near current_sample_pos)\n",
    "            # ... (Sync logic remains same) ...\n",
    "            \n",
    "            start_search = max(0, current_sample_pos - search_window)\n",
    "            end_search = min(len(self.freqs), current_sample_pos + search_window)\n",
    "            \n",
    "            best_sync_end = -1\n",
    "            \n",
    "            if end_search > start_search:\n",
    "                local_freqs = self.freqs[start_search:end_search]\n",
    "                is_sync = (local_freqs > freq_min) & (local_freqs < freq_max)\n",
    "                \n",
    "                edges = np.diff(is_sync.astype(int))\n",
    "                falling_edges = np.where(edges == -1)[0]\n",
    "                \n",
    "                if len(falling_edges) > 0:\n",
    "                     candidates_abs = falling_edges + start_search\n",
    "                     dists = np.abs(candidates_abs - current_sample_pos)\n",
    "                     best_idx = np.argmin(dists)\n",
    "                     \n",
    "                     edge_pos = candidates_abs[best_idx]\n",
    "                     check_start =  max(0, edge_pos - min_sync_len)\n",
    "                     if np.mean(is_sync[(check_start-start_search):(edge_pos-start_search)]) > 0.8:\n",
    "                         best_sync_end = edge_pos\n",
    "\n",
    "            if best_sync_end != -1:\n",
    "                current_sample_pos = best_sync_end\n",
    "\n",
    "            # 2. Decode the line at current_sample_pos\n",
    "            # Apply shift for visual alignment (does not affect PLL/Flywheel timing)\n",
    "            # Support per-line shift (wobble)\n",
    "            line_shift = shift\n",
    "            if isinstance(shift, (list, np.ndarray)):\n",
    "                if line_idx < len(shift):\n",
    "                    line_shift = shift[line_idx]\n",
    "                else:\n",
    "                    line_shift = shift[-1]\n",
    "            \n",
    "            effective_start = current_sample_pos + int(line_shift)\n",
    "            \n",
    "            # Use effective_start as base for all extraction\n",
    "            sync_end = effective_start\n",
    "            \n",
    "            # Check limits\n",
    "            if sync_end + uv_end >= len(self.freqs):\n",
    "                break\n",
    "\n",
    "            # Y Channel\n",
    "            y_freqs = self.freqs[sync_end + y_start : sync_end + y_end]\n",
    "            if len(y_freqs) > 0:\n",
    "                y_pixels_freq = signal.resample(y_freqs, self.config.width)\n",
    "                y_vals = (y_pixels_freq - common.BLACK_FREQ) * 255.0 / (common.WHITE_FREQ - common.BLACK_FREQ)\n",
    "                y_image[line_idx] = y_vals\n",
    "            \n",
    "            # Color Mode Detection & Phase Locking\n",
    "            # Expected frequencies: Even=1500Hz, Odd=2300Hz\n",
    "            # Separator is located after Y scan\n",
    "            \n",
    "            margin = int(sep_samples * 0.25)\n",
    "            curr_sep_start = int(sync_end + sep_start + margin)\n",
    "            curr_sep_end = int(sync_end + sep_start + sep_samples - margin)\n",
    "            \n",
    "            # Measure actual separator frequency\n",
    "            measured_freq = 0\n",
    "            if curr_sep_end < len(self.freqs):\n",
    "                sep_freqs = self.freqs[curr_sep_start : curr_sep_end]\n",
    "                if len(sep_freqs) > 0:\n",
    "                    measured_freq = np.mean(sep_freqs)\n",
    "            \n",
    "            # Phase Correction Logic (Hysteresis)\n",
    "            # Only correct if we are VERY confident.\n",
    "            # Even (1500) <-> Odd (2300). Midpoint ~1900.\n",
    "            # Strong Even: < 1700. Strong Odd: > 2100.\n",
    "            \n",
    "            strong_odd = measured_freq > 2100\n",
    "            strong_even = measured_freq > 0 and measured_freq < 1700\n",
    "            \n",
    "            mismatch_detected = False\n",
    "            \n",
    "            if current_phase_is_odd:\n",
    "                if strong_even:\n",
    "                    mismatch_detected = True\n",
    "            else:\n",
    "                if strong_odd:\n",
    "                    mismatch_detected = True\n",
    "            \n",
    "            if mismatch_detected:\n",
    "                phase_mismatch_counter += 1\n",
    "            else:\n",
    "                # Decay the counter if signal agrees or is ambiguous (noise)\n",
    "                # We decay slowly aka we require a few good lines to trust stability?\n",
    "                # Or fast decay? Fast decay is better to recover from false positives.\n",
    "                phase_mismatch_counter = max(0, phase_mismatch_counter - 1)\n",
    "                \n",
    "            if phase_mismatch_counter >= 3:\n",
    "                # 3 lines of strong contrary evidence -> Flip Phase\n",
    "                current_phase_is_odd = not current_phase_is_odd\n",
    "                phase_mismatch_counter = 0\n",
    "            \n",
    "            # UV Channel\n",
    "            uv_freqs = self.freqs[sync_end + uv_start : sync_end + uv_end]\n",
    "            if len(uv_freqs) > 0:\n",
    "                uv_pixels_freq = signal.resample(uv_freqs, self.config.width)\n",
    "                uv_vals = (uv_pixels_freq - common.BLACK_FREQ) * 255.0 / (common.WHITE_FREQ - common.BLACK_FREQ)\n",
    "                \n",
    "                if current_phase_is_odd:\n",
    "                     # Odd Line -> U Scan\n",
    "                     last_u = uv_vals\n",
    "                     # V uses previous\n",
    "                else:\n",
    "                     # Even Line -> V Scan\n",
    "                     last_v = uv_vals\n",
    "                     # U uses previous\n",
    "            \n",
    "            u_image[line_idx] = last_u\n",
    "            v_image[line_idx] = last_v\n",
    "            \n",
    "            # 3. Advance Clock & Phase\n",
    "            current_sample_pos += samples_per_line\n",
    "            current_phase_is_odd = not current_phase_is_odd\n",
    "        \n",
    "        # Convert to RGB\n",
    "        r, g, b = common.yuv_to_rgb(y_image, u_image, v_image)\n",
    "        \n",
    "        rgb_img = np.stack((r, g, b), axis=-1).astype(np.uint8)\n",
    "        img = Image.fromarray(rgb_img)\n",
    "        img.save(output_path)\n",
    "        print(f\"Decoded image saved to {output_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(description=\"Python Robot36 SSTV Decoder\")\n",
    "    parser.add_argument(\"input_file\", help=\"Path to input audio file (WAV, MP3, etc.)\")\n",
    "    parser.add_argument(\"output_image\", help=\"Path to output image\")\n",
    "    parser.add_argument(\"--width\", type=int, default=320, help=\"Input width (default: 320)\")\n",
    "    parser.add_argument(\"--height\", type=int, default=240, help=\"Input height (default: 240)\")\n",
    "    parser.add_argument(\"--shift\", type=int, default=0, help=\"Phase shift in samples (default: 0)\")\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    decoder = SSTVDecoder(args.input_file, args.width, args.height)\n",
    "    decoder.decode(args.output_image, shift=args.shift)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile sstv_filter.py\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import io\n",
    "import subprocess\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# Add current directory to path to import encoder/decoder\n",
    "sys.path.append(os.path.dirname(os.path.abspath(__file__)))\n",
    "\n",
    "from encoder import SSTVEncoder\n",
    "from decoder import SSTVDecoder\n",
    "import common\n",
    "\n",
    "def get_resolution_from_preset(preset):\n",
    "    presets = {\n",
    "        'default': (320, 240),\n",
    "        'ntsc': (720, 480),\n",
    "        'pal': (720, 576),\n",
    "        'robot36': (320, 240),\n",
    "        'martin1': (320, 256),\n",
    "        'scott1': (320, 256),\n",
    "        '144p': (256, 144),\n",
    "        '240p': (426, 240),\n",
    "        '360p': (640, 360),\n",
    "        '480p': (854, 480),\n",
    "        '720p': (1280, 720),\n",
    "        '1080p': (1920, 1080),\n",
    "    }\n",
    "    return presets.get(preset.lower(), (320, 240))\n",
    "\n",
    "\n",
    "\n",
    "def apply_compression(wav_bytes, bitrate):\n",
    "    \"\"\"\n",
    "    Compresses WAV bytes (PCM) to MP3/Opus using ffmpeg, then decompresses back to WAV bytes.\n",
    "    This simulates the transmission loss.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Determine codec and container based on bitrate\n",
    "        # MP3 standard floor is often 8kbps or 32kbps depending on sample rate.\n",
    "        # Opus can go very low (1k).\n",
    "        \n",
    "        # Extract numerical value from bitrate string\n",
    "        bk = int(''.join(filter(str.isdigit, bitrate)))\n",
    "        \n",
    "        codec = 'libmp3lame'\n",
    "        fmt = 'mp3'\n",
    "        extra_args = []\n",
    "        \n",
    "        if bk < 4:\n",
    "            # Use Speex for extremely low bitrates (< 6k)\n",
    "            # Opus hits a floor ~6k. Speex can go down to ~2k (Narrowband).\n",
    "            codec = 'libspeex'\n",
    "            fmt = 'ogg'\n",
    "            # Speex NB requires 8k sample rate\n",
    "            # -vad 0 disables VAD to ensure constant transmission if possible (though speex is inherently VBR-ish)\n",
    "            extra_args = ['-ar', '8000']\n",
    "        elif bk < 8:\n",
    "            # MP3 typically doesn't support < 8k. Use Opus.\n",
    "            codec = 'libopus'\n",
    "            fmt = 'opus'\n",
    "            # Low bitrate Opus usually wants 48k (internal) but acceptable.\n",
    "            # Add voip application tune for extreme low bitrates\n",
    "            extra_args = ['-application', 'voip', '-ar', '8000']\n",
    "        elif bk < 32:\n",
    "            # MP3 at <32k often requires lower sample rate (16k, 22.05k, 24k)\n",
    "            # 48k input might cause encoder failure.\n",
    "            # Let's force resampling to 16k for these intermediate bitrates\n",
    "            extra_args = ['-ar', '16000']\n",
    "            \n",
    "        cmd_enc = [\n",
    "            'ffmpeg', '-y', '-f', 'wav', '-i', 'pipe:0',\n",
    "            '-c:a', codec, '-b:a', bitrate\n",
    "        ] + extra_args + ['-f', fmt, 'pipe:1']\n",
    "        \n",
    "        # 1. Encode\n",
    "        process_enc = subprocess.Popen(\n",
    "            cmd_enc, stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE\n",
    "        )\n",
    "        compressed_data, enc_err = process_enc.communicate(input=wav_bytes)\n",
    "        \n",
    "        if process_enc.returncode != 0:\n",
    "            print(f\"Warning: Compression encoding failed. Using original audio.\")\n",
    "            print(f\"FFmpeg Error: {enc_err.decode('utf-8', errors='ignore')}\")\n",
    "            return wav_bytes\n",
    "\n",
    "        # 2. Decode back to WAV (PCM)\n",
    "        # Note: ffmpeg auto-detects codec from content usually, but pipe might need hint if no header?\n",
    "        # MP3/Opus in pipe usually has headers.\n",
    "        cmd_dec = [\n",
    "            'ffmpeg', '-y', '-i', 'pipe:0',\n",
    "            '-f', 'wav', 'pipe:1'\n",
    "        ]\n",
    "        \n",
    "        process_dec = subprocess.Popen(\n",
    "            cmd_dec, stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE\n",
    "        )\n",
    "        wav_pcm, dec_err = process_dec.communicate(input=compressed_data)\n",
    "        \n",
    "        if process_dec.returncode != 0:\n",
    "            print(f\"Warning: Compression decoding failed. Using original audio.\")\n",
    "            print(f\"FFmpeg Decode Error: {dec_err.decode('utf-8', errors='ignore')}\")\n",
    "            return wav_bytes\n",
    "            \n",
    "        return wav_pcm\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during compression: {e}\")\n",
    "        return wav_bytes\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser(description=\"SSTV Image Filter Tool\")\n",
    "    parser.add_argument(\"input_image\", help=\"Input image path\")\n",
    "    parser.add_argument(\"output_image\", help=\"Output image path\")\n",
    "    \n",
    "    # Resolution arguments\n",
    "    group = parser.add_mutually_exclusive_group()\n",
    "    group.add_argument(\"--preset\", help=\"Resolution preset (default, ntsc, pal, 144p, etc.)\", default=\"default\")\n",
    "    group.add_argument(\"--res\", help=\"Custom resolution WxH (e.g. 640x480)\")\n",
    "    \n",
    "    # Compression\n",
    "    parser.add_argument(\"-k\", \"--bitrate\", help=\"Audio bitrate (e.g. 320k, 64k, 1k)\", default=None)\n",
    "    \n",
    "    # Save intermediate audio\n",
    "    parser.add_argument(\"--save-audio\", help=\"Path to save the generated audio WAV file\", default=None)\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    # Determine resolution\n",
    "    width, height = 320, 240\n",
    "    if args.res:\n",
    "        try:\n",
    "            w, h = map(int, args.res.split('x'))\n",
    "            width, height = w, h\n",
    "        except:\n",
    "            print(\"Invalid resolution format. Using default.\")\n",
    "    else:\n",
    "        width, height = get_resolution_from_preset(args.preset)\n",
    "        \n",
    "    print(f\"Processing image: {args.input_image}\")\n",
    "    print(f\"Target Resolution: {width}x{height}\")\n",
    "    \n",
    "    # 1. Encode\n",
    "    print(\"Encoding to SSTV...\")\n",
    "    encoder = SSTVEncoder(args.input_image, width, height)\n",
    "    \n",
    "    # In-memory WAV buffer\n",
    "    wav_buffer = io.BytesIO()\n",
    "    encoder.write_wav(wav_buffer)\n",
    "    wav_bytes = wav_buffer.getvalue()\n",
    "    \n",
    "    # 2. Compress (Optional)\n",
    "    if args.bitrate:\n",
    "        print(f\"Applying compression ({args.bitrate})...\")\n",
    "        wav_bytes = apply_compression(wav_bytes, args.bitrate)\n",
    "        \n",
    "    # Save audio if requested\n",
    "    if args.save_audio:\n",
    "        with open(args.save_audio, 'wb') as f:\n",
    "            f.write(wav_bytes)\n",
    "        print(f\"Audio saved to {args.save_audio}\")\n",
    "        \n",
    "    # 3. Decode\n",
    "    print(\"Decoding SSTV...\")\n",
    "    # Wrap bytes in BytesIO for wavfile.read\n",
    "    decode_buffer = io.BytesIO(wav_bytes)\n",
    "    \n",
    "    decoder = SSTVDecoder(decode_buffer, width, height)\n",
    "    decoder.decode(args.output_image)\n",
    "    \n",
    "    print(f\"Finished. Saved to {args.output_image}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile video_sstv.py\n",
    "\n",
    "import cv2\n",
    "import argparse\n",
    "import sys\n",
    "import os\n",
    "import multiprocessing\n",
    "import tempfile\n",
    "import subprocess\n",
    "import shutil\n",
    "import io\n",
    "import time\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# Import local modules\n",
    "sys.path.append(os.path.dirname(os.path.abspath(__file__)))\n",
    "from encoder import SSTVEncoder\n",
    "from decoder import SSTVDecoder\n",
    "from sstv_filter import get_resolution_from_preset, apply_compression\n",
    "import common\n",
    "\n",
    "def process_frame_task(args):\n",
    "    \"\"\"\n",
    "    Worker function to process a single frame.\n",
    "    args: (frame_bgr, frame_idx, config_dict)\n",
    "    Returns: (frame_idx, processed_frame_bgr)\n",
    "    \"\"\"\n",
    "    frame_bgr, frame_idx, config = args\n",
    "    \n",
    "    try:\n",
    "        # 1. Resize to Target SSTV Resolution\n",
    "        target_w, target_h = config['target_size']\n",
    "        original_h, original_w = frame_bgr.shape[:2]\n",
    "        \n",
    "        # Convert BGR to RGB (PIL)\n",
    "        frame_rgb = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2RGB)\n",
    "        pil_img = Image.fromarray(frame_rgb)\n",
    "        \n",
    "        # Resize to SSTV res\n",
    "        # Save to temp file for Encoder (Encoder takes path) -> Optimization: Encoder should take PIL Image?\n",
    "        # Looking at encoder.py, it takes image_path. \n",
    "        # We should modify encoder to accept image object or save temp.\n",
    "        # For now, save temp to be safe standard.\n",
    "        \n",
    "        # Unique temp file for this worker (Only for intermediate WAV/PNG if needed)\n",
    "        pid = multiprocessing.current_process().pid\n",
    "        # temp_in = os.path.join(config['temp_dir'], f\"frame_{frame_idx}_{pid}_in.png\") # Removed: In-memory\n",
    "        temp_out_img = os.path.join(config['temp_dir'], f\"frame_{frame_idx}_{pid}_out.png\")\n",
    "        \n",
    "        # pil_img.save(temp_in) # Removed\n",
    "        \n",
    "        # 2. Encode\n",
    "        # Encoder accepts PIL Image directly now!\n",
    "        encoder = SSTVEncoder(pil_img, target_w, target_h, sample_rate=48000)\n",
    "        \n",
    "        # Write WAV to memory buffer to avoid disk I/O if possible? \n",
    "        # encoder.write_wav takes file_object.\n",
    "        wav_buffer = io.BytesIO()\n",
    "        encoder.write_wav(wav_buffer)\n",
    "        wav_bytes = wav_buffer.getvalue()\n",
    "        \n",
    "        # 3. Compress (Simulate Channel)\n",
    "        if config['bitrate']:\n",
    "            wav_bytes = apply_compression(wav_bytes, config['bitrate'])\n",
    "            \n",
    "        # 4. Decode\n",
    "        # Decoder takes file-like object\n",
    "        # Suppress WavFileWarning from scipy\n",
    "        import warnings\n",
    "        from scipy.io import wavfile\n",
    "        warnings.filterwarnings(\"ignore\", category=wavfile.WavFileWarning)\n",
    "        \n",
    "        # Calculate Random parameters for this frame\n",
    "        # Seed = Base + FrameIdx\n",
    "        rng = np.random.RandomState(config['base_seed'] + frame_idx)\n",
    "        \n",
    "        # 1. Random Shift (Global Phase Jitter)\n",
    "        # Add to static shift\n",
    "        base_shift = config['shift']\n",
    "        if config['rand_shift_range'] > 0:\n",
    "            jitter = rng.randint(-config['rand_shift_range'], config['rand_shift_range'] + 1)\n",
    "            base_shift += jitter\n",
    "            \n",
    "        # 1.5 Random Wobble (Line Tearing)\n",
    "        if config['rand_wobble_max'] > 0:\n",
    "            # Generate array of random shifts per line\n",
    "            wobble = rng.randint(-config['rand_wobble_max'], config['rand_wobble_max'] + 1, size=target_h)\n",
    "            frame_shift = wobble + base_shift\n",
    "        else:\n",
    "            frame_shift = base_shift\n",
    "            \n",
    "        # 2. Random Skew (Clock Drift)\n",
    "        # sample_rate_skew: e.g. 0.0005\n",
    "        frame_skew = 0.0\n",
    "        if config['rand_skew_max'] > 0:\n",
    "            frame_skew = rng.uniform(-config['rand_skew_max'], config['rand_skew_max'])\n",
    "        \n",
    "        decode_buffer = io.BytesIO(wav_bytes)\n",
    "        # Pass skew to decoder\n",
    "        decoder = SSTVDecoder(\n",
    "            decode_buffer, target_w, target_h, \n",
    "            force_device=config['device'], \n",
    "            verbose=False,\n",
    "            sample_rate_skew=frame_skew\n",
    "        )\n",
    "        \n",
    "        # Decoder.decode saves to file. \n",
    "        # decoder.decode calls demodulate\n",
    "        decoder.decode(temp_out_img, shift=frame_shift)\n",
    "        \n",
    "        # 5. Read back and Resize to Output (Original or Target?)\n",
    "        # Usually video filters output same resolution as input unless specified.\n",
    "        # But feasibility report said: \"Resize(1080p) -> Output\".\n",
    "        # So we resize back to ORIGINAL video resolution.\n",
    "        \n",
    "        if os.path.exists(temp_out_img):\n",
    "            processed_pil = Image.open(temp_out_img).convert('RGB')\n",
    "            # Resize back to original video size\n",
    "            processed_pil = processed_pil.resize((original_w, original_h), Image.Resampling.NEAREST) # Nearest for glitch look? Or Lanczos?\n",
    "            # Let's use Bilinear or Lanczos for better quality upscaling.\n",
    "            processed_pil = processed_pil.resize((original_w, original_h), Image.Resampling.LANCZOS)\n",
    "            \n",
    "            processed_rgb = np.array(processed_pil)\n",
    "            processed_bgr = cv2.cvtColor(processed_rgb, cv2.COLOR_RGB2BGR)\n",
    "        else:\n",
    "            # Fallback\n",
    "            processed_bgr = frame_bgr\n",
    "\n",
    "        # Cleanup\n",
    "        try:\n",
    "            # temp_in is removed/in-memory now\n",
    "            if os.path.exists(temp_out_img): os.remove(temp_out_img)\n",
    "        except:\n",
    "            pass\n",
    "            \n",
    "        return (frame_idx, processed_bgr)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing frame {frame_idx}: {e}\")\n",
    "        return (frame_idx, frame_bgr) # Return original on failure\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser(description=\"Convert Video to SSTV Style\")\n",
    "    parser.add_argument(\"input_video\", help=\"Path to input video file\")\n",
    "    parser.add_argument(\"output_video\", nargs='?', help=\"Path to output video file (optional if --no-video is used)\")\n",
    "    \n",
    "    # SSTV Config\n",
    "    parser.add_argument(\"--preset\", default=\"default\", help=\"SSTV Mode Preset (default, ntsc, 1080p etc)\")\n",
    "    parser.add_argument(\"--width\", type=int, help=\"Override SSTV processing width\")\n",
    "    parser.add_argument(\"--height\", type=int, help=\"Override SSTV processing height\")\n",
    "    parser.add_argument(\"--shift\", type=int, default=0, help=\"Phase shift (horizontal alignment)\")\n",
    "    parser.add_argument(\"-k\", \"--bitrate\", help=\"Audio bitrate simulation (e.g. 32k, 8k, 4k)\")\n",
    "    \n",
    "    # Video Config\n",
    "    parser.add_argument(\"--fps\", type=float, help=\"Output FPS (default: same as input)\")\n",
    "    parser.add_argument(\"--no-audio\", action=\"store_true\", help=\"Do not copy audio from input\")\n",
    "    parser.add_argument(\"--no-video\", action=\"store_true\", help=\"Do not generate output video file (process frames only)\")\n",
    "    parser.add_argument(\"--workers\", type=int, default=multiprocessing.cpu_count(), help=\"Number of parallel workers\")\n",
    "    parser.add_argument(\"--device\", choices=['cpu', 'cuda', 'mps'], default=None, help=\"Force acceleration device\")\n",
    "    \n",
    "    parser.add_argument('--frames-dir', type=str, help=\"Directory to save processed frames. Defaults to './<video_name>_frames'.\")\n",
    "    parser.add_argument('--clean-frames', action='store_true', help=\"Delete frames directory after processing.\")\n",
    "    parser.add_argument('--start', type=int, default=0, help=\"Start frame index.\")\n",
    "    parser.add_argument('--end', type=int, default=None, help=\"End frame index.\")\n",
    "    parser.add_argument('--index-mode', type=str, choices=['input', 'output'], default='input', help=\"Whether start/end indices refer to 'input' (original) or 'output' (target) video frames.\")\n",
    "    \n",
    "    parser.add_argument('--random-shift-range', type=int, default=0, help=\"Randomize horizontal shift per frame by +/- N pixels (Global Jitter).\")\n",
    "    parser.add_argument('--random-wobble-max', type=int, default=0, help=\"Randomize horizontal shift per scanline by +/- N pixels (Line Tearing).\")\n",
    "    parser.add_argument('--random-skew', type=float, default=0.0, help=\"Randomize sample rate skew per frame by +/- F (e.g. 0.0005) (Clock Drift).\")\n",
    "    parser.add_argument('--seed', type=int, default=None, help=\"Random seed for reproducible effects.\")\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "\n",
    "    if not args.output_video and not args.no_video:\n",
    "        parser.error(\"the following arguments are required: output_video (unless --no-video is specified)\")\n",
    "    \n",
    "    print(f\"--- Video SSTV Processing ---\")\n",
    "    print(f\"Input: {args.input_video}\")\n",
    "    # Resolution parsed later\n",
    "    print(f\"Bitrate: {args.bitrate if args.bitrate else 'Lossless/PCM'}\")\n",
    "    print(f\"Workers: {args.workers}\")\n",
    "    print(f\"Device: {args.device if args.device else 'Auto'}\")\n",
    "    \n",
    "    # 1. Open Video\n",
    "    cap = cv2.VideoCapture(args.input_video)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video.\")\n",
    "        sys.exit(1)\n",
    "        \n",
    "    original_fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    width_video = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height_video = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    \n",
    "    target_fps = args.fps if args.fps else original_fps\n",
    "    \n",
    "    # Smart Resolution Logic\n",
    "    # 0 -> Keep Original\n",
    "    # -1 (or negative) -> Scale proportionally\n",
    "    # Both <= 0 -> Keep Original\n",
    "    \n",
    "    base_w, base_h = get_resolution_from_preset(args.preset)\n",
    "    \n",
    "    # Start with base or overrides\n",
    "    # If args.width is None (not provided), use base. If provided (0, -1, 100), use arg.\n",
    "    req_w = args.width if args.width is not None else (base_w if args.preset != 'default' else 0) \n",
    "    req_h = args.height if args.height is not None else (base_h if args.preset != 'default' else 0)\n",
    "    \n",
    "    # If preset is default and no args, args.width is None, base is 320.\n",
    "    # Current logic: args.preset default is \"default\".\n",
    "    # We want: \n",
    "    # If user didn't specify preset OR width/height -> Default 320x240 (Robot36ish)\n",
    "    # If user specified preset -> use preset res\n",
    "    # If user specified width/height -> override\n",
    "    \n",
    "    # If overrides exist, they take precedence.\n",
    "    raw_w = args.width if args.width is not None else None\n",
    "    raw_h = args.height if args.height is not None else None\n",
    "    \n",
    "    if raw_w is None and raw_h is None:\n",
    "        # Pure preset mode\n",
    "        target_w, target_h = base_w, base_h\n",
    "    else:\n",
    "        # Custom / Override mode\n",
    "        w_val = raw_w if raw_w is not None else 0\n",
    "        h_val = raw_h if raw_h is not None else 0\n",
    "        \n",
    "        ar_video = width_video / height_video\n",
    "        \n",
    "        # 1. Resolve '0' to Original Dimension\n",
    "        # 2. Mark '<0' as specific flag for calculation\n",
    "        \n",
    "        final_w = w_val\n",
    "        if w_val == 0:\n",
    "            final_w = width_video\n",
    "        \n",
    "        final_h = h_val\n",
    "        if h_val == 0:\n",
    "            final_h = height_video\n",
    "            \n",
    "        # 3. Handle Auto-Scale Flags (<0)\n",
    "        # Note: final_w/h are now either >0 or <0. They cannot be 0.\n",
    "        \n",
    "        if final_w < 0 and final_h < 0:\n",
    "             # Both -1 -> Keep Original\n",
    "             target_w, target_h = width_video, height_video\n",
    "        elif final_w < 0:\n",
    "             # Width is -1, Height is concrete (>0)\n",
    "             # Scale width to match height using aspect ratio\n",
    "             # w = h * ar\n",
    "             target_h = final_h\n",
    "             target_w = int(final_h * ar_video)\n",
    "        elif final_h < 0:\n",
    "             # Height is -1, Width is concrete (>0)\n",
    "             # Scale height to match width\n",
    "             # h = w / ar\n",
    "             target_w = final_w\n",
    "             target_h = int(final_w / ar_video)\n",
    "        else:\n",
    "             # Both concrete\n",
    "             target_w, target_h = final_w, final_h\n",
    "\n",
    "    # Ensure even dimensions (video codecs prefer them)\n",
    "    if target_w % 2 != 0: target_w += 1\n",
    "    if target_h % 2 != 0: target_h += 1\n",
    "\n",
    "    print(f\"Video Info: {width_video}x{height_video} @ {original_fps}fps ({total_frames} frames)\")\n",
    "    print(f\"Target Resolution: {target_w}x{target_h}\")\n",
    "    \n",
    "    # Create Frames Directory\n",
    "    if args.frames_dir:\n",
    "        temp_dir = args.frames_dir\n",
    "    else:\n",
    "        # Default: current_dir / <video_name>_frames\n",
    "        base_name = os.path.splitext(os.path.basename(args.input_video))[0]\n",
    "        temp_dir = os.path.join(os.getcwd(), f\"{base_name}_frames\")\n",
    "    \n",
    "    os.makedirs(temp_dir, exist_ok=True)\n",
    "    print(f\"Frames directory: {temp_dir}\")\n",
    "    \n",
    "    # 2. Extract Audio (if needed)\n",
    "    audio_path = None\n",
    "    # Frame Range Logic\n",
    "    fps_ratio = original_fps / target_fps\n",
    "    \n",
    "    start_frame_input = args.start\n",
    "    end_frame_input = args.end if args.end is not None else total_frames\n",
    "    \n",
    "    if args.index_mode == 'output':\n",
    "        # Convert output index to input index\n",
    "        start_frame_input = int(start_frame_input * fps_ratio)\n",
    "        end_frame_input = int(end_frame_input * fps_ratio)\n",
    "        \n",
    "    start_frame_input = max(0, start_frame_input)\n",
    "    end_frame_input = min(int(total_frames), end_frame_input)\n",
    "    \n",
    "    print(f\"Processing range (Input Indices): {start_frame_input} to {end_frame_input}\")\n",
    "\n",
    "    # 2. Extract Audio (Segment)\n",
    "    audio_path = os.path.join(temp_dir, \"extracted_audio.wav\")\n",
    "    \n",
    "    start_time_sec = start_frame_input / original_fps\n",
    "    duration_sec = (end_frame_input - start_frame_input) / original_fps\n",
    "    \n",
    "    if not args.no_audio:\n",
    "        print(f\"Extracting audio segment: Start={start_time_sec:.2f}s, Dur={duration_sec:.2f}s\")\n",
    "        try:\n",
    "            # -ss before -i is fast seek (keyframe), but less accurate?\n",
    "            # input is video.\n",
    "            # -ss after -i is frame accurate decoding.\n",
    "            # We want logic: input -> extract -ss ... -t ...\n",
    "            cmd = [\n",
    "                'ffmpeg', '-y', '-i', args.input_video, \n",
    "                '-ss', str(start_time_sec),\n",
    "                '-t', str(duration_sec),\n",
    "                '-vn', '-acodec', 'pcm_s16le', '-ar', '44100', audio_path\n",
    "            ]\n",
    "            subprocess.run(cmd, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Audio extraction failed: {e}\")\n",
    "            audio_path = None\n",
    "    else:\n",
    "        audio_path = None\n",
    "\n",
    "    # Seek Video\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame_input)\n",
    "    \n",
    "    # 3. Process Frames\n",
    "    # 3. Process Frames\n",
    "    frames_dir = temp_dir\n",
    "    # os.makedirs(frames_dir, exist_ok=True) # Already created\n",
    "    \n",
    "    # Random Base Seed\n",
    "    if args.seed is not None:\n",
    "        base_seed = args.seed\n",
    "    else:\n",
    "        base_seed = int(time.time())\n",
    "    print(f\"Random Seed: {base_seed}\")\n",
    "\n",
    "    config = {\n",
    "        'target_size': (target_w, target_h),\n",
    "        'temp_dir': temp_dir,\n",
    "        'bitrate': args.bitrate,\n",
    "        'shift': args.shift,\n",
    "        'device': args.device,\n",
    "        # Random Config\n",
    "        'rand_shift_range': args.random_shift_range,\n",
    "        'rand_wobble_max': args.random_wobble_max,\n",
    "        'rand_skew_max': args.random_skew,\n",
    "        'base_seed': base_seed\n",
    "    }\n",
    "    \n",
    "    \n",
    "    read_count = start_frame_input\n",
    "    process_count = 0 \n",
    "    \n",
    "    pool = multiprocessing.Pool(processes=args.workers)\n",
    "    results = []\n",
    "    \n",
    "    # Buffer for async results (index, object)\n",
    "    pending_results = {} # index -> AsyncResult\n",
    "    next_write_idx = 0\n",
    "    \n",
    "    acc_error = 0.0\n",
    "    \n",
    "    try:\n",
    "        while True:\n",
    "            if read_count >= end_frame_input:\n",
    "                break\n",
    "                \n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            \n",
    "            # Decimation Logic\n",
    "            process_this = False\n",
    "            if args.fps:\n",
    "                acc_error += 1\n",
    "                if acc_error >= frame_interval:\n",
    "                    process_this = True\n",
    "                    acc_error -= frame_interval\n",
    "            else:\n",
    "                process_this = True\n",
    "                \n",
    "            if process_this:\n",
    "                # Dispatch\n",
    "                idx = process_count\n",
    "                \n",
    "                # Apply processing asynchronously\n",
    "                res = pool.apply_async(process_frame_task, args=((frame, idx, config),))\n",
    "                pending_results[idx] = res\n",
    "                process_count += 1\n",
    "                \n",
    "                # Flow control: don't OOM\n",
    "                # Check for finished tasks dynamically\n",
    "                while len(pending_results) > args.workers * 2:\n",
    "                    # Find any ready task\n",
    "                    finished_indices = []\n",
    "                    for p_idx, p_res in pending_results.items():\n",
    "                        if p_res.ready():\n",
    "                            r_idx, r_frame = p_res.get()\n",
    "                            \n",
    "                            # Save Immediate\n",
    "                            # Use r_idx (which tracks 0, 1, 2...) for filename\n",
    "                            out_path = os.path.join(frames_dir, f\"frame_{r_idx:05d}.png\")\n",
    "                            success = cv2.imwrite(out_path, r_frame)\n",
    "                            if not success:\n",
    "                                print(f\"Error: Failed to write {out_path}\")\n",
    "                                \n",
    "                            finished_indices.append(p_idx)\n",
    "                            print(f\"Processed frame {r_idx+1}/...\", end='\\r')\n",
    "                    \n",
    "                    # Remove finished\n",
    "                    for p_idx in finished_indices:\n",
    "                        del pending_results[p_idx]\n",
    "                    \n",
    "                    # If still too many, sleep brief\n",
    "                    if len(pending_results) > args.workers * 2:\n",
    "                        time.sleep(0.01) # Brief yield\n",
    "                        \n",
    "            read_count += 1\n",
    "            \n",
    "        # Drain rest\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "        \n",
    "        # Collect remaining (all should be ready now)\n",
    "        for p_idx, p_res in pending_results.items():\n",
    "             r_idx, r_frame = p_res.get()\n",
    "             \n",
    "             out_path = os.path.join(frames_dir, f\"frame_{r_idx:05d}.png\")\n",
    "             success = cv2.imwrite(out_path, r_frame)\n",
    "             if not success:\n",
    "                 print(f\"Error: Failed to write {out_path}\")\n",
    "             print(f\"Processed frame {r_idx+1}/{process_count}\", end='\\r')\n",
    "        \n",
    "        # Clear buffer\n",
    "        pending_results.clear()\n",
    "    \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nStopping...\")\n",
    "        pool.terminate()\n",
    "        \n",
    "    finally:\n",
    "        cap.release()\n",
    "        print(\"\\nFrames extraction complete.\")\n",
    "        \n",
    "    # 4. Assemble Video with FFmpeg\n",
    "    if not args.no_video and args.output_video:\n",
    "        print(\"Assembling video...\")\n",
    "        final_output = args.output_video\n",
    "        \n",
    "        # FFmpeg command to assemble frames + audio\n",
    "        # -framerate must be before -i image\n",
    "        assemble_cmd = [\n",
    "            'ffmpeg', '-y', \n",
    "            '-framerate', str(target_fps),\n",
    "            '-start_number', '0',\n",
    "            '-i', os.path.join(frames_dir, 'frame_%05d.png')\n",
    "        ]\n",
    "        \n",
    "        if audio_path and os.path.exists(audio_path):\n",
    "            assemble_cmd += ['-i', audio_path, '-c:v', 'libx264', '-pix_fmt', 'yuv420p', '-c:a', 'aac', '-shortest', final_output]\n",
    "        else:\n",
    "            assemble_cmd += ['-c:v', 'libx264', '-pix_fmt', 'yuv420p', '-an', final_output]\n",
    "            \n",
    "        subprocess.run(assemble_cmd, stdout=subprocess.DEVNULL, stderr=subprocess.PIPE)\n",
    "        print(f\"\\nDone! Video saved: {final_output}\")\n",
    "    else:\n",
    "        print(\"\\nSkipping video assembly (--no-video selected or no output file).\")\n",
    "    \n",
    "    # Cleanup\n",
    "    if args.clean_frames:\n",
    "        print(f\"Cleaning up frames directory: {temp_dir}\")\n",
    "        shutil.rmtree(temp_dir, ignore_errors=True)\n",
    "    else:\n",
    "        print(f\"Frames saved in: {temp_dir}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 3. Setup Input Source\n",
    "import os\n",
    "from google.colab import files\n",
    "from google.colab import drive\n",
    "\n",
    "source_type = \"Mount Google Drive\" #@param [\"Mount Google Drive\", \"Upload File\"]\n",
    "\n",
    "if source_type == \"Mount Google Drive\":\n",
    "    drive.mount('/content/drive')\n",
    "    print(\"Google Drive mounted at /content/drive\")\n",
    "elif source_type == \"Upload File\":\n",
    "    uploaded = files.upload()\n",
    "    if uploaded:\n",
    "        fname = list(uploaded.keys())[0]\n",
    "        print(f\"File uploaded to: /content/{fname}\")\n",
    "        print(\"Please copy this path to the 'input_path' field below.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 4. Run Process\n",
    "\n",
    "input_path = \"/content/drive/MyDrive/videos/test.mp4\" #@param {type:\"string\"}\n",
    "output_filename = \"/content/drive/MyDrive/videos/output_sstv.mp4\" #@param {type:\"string\"}\n",
    "\n",
    "#@markdown ### Basic Settings\n",
    "preset = \"ntsc\" #@param [\"ntsc\", \"pal\", \"robot36\", \"martin1\", \"scott1\", \"144p\", \"240p\", \"360p\", \"480p\", \"720p\", \"1080p\", \"Custom\"]\n",
    "custom_width = -1 #@param {type:\"integer\", help:\"Only used if preset is Custom. 0=Original, -1=Scale by Ratio\"}\n",
    "custom_height = -1 #@param {type:\"integer\", help:\"Only used if preset is Custom. 0=Original, -1=Scale by Ratio\"}\n",
    "bitrate = \"12k\" #@param [\"Lossless\", \"320k\", \"256k\", \"192k\", \"128k\", \"96k\", \"64k\", \"48k\", \"32k\", \"24k\", \"16k\", \"12k\", \"8k\", \"4k\", \"2k\"]\n",
    "workers = 4 #@param {type:\"integer\"}\n",
    "no_video = False #@param {type:\"boolean\"}\n",
    "\n",
    "#@markdown ### Random Glitch Effects\n",
    "random_shift_range = 5 #@param {type:\"integer\", help:\"Horizontal shake amplitude (pixels)\"}\n",
    "random_wobble_max = 3 #@param {type:\"integer\", help:\"Scanline tearing/wobble amplitude (pixels)\"}\n",
    "random_skew = 0.0005 #@param {type:\"number\", help:\"Clock drift/slant factor (e.g. 0.0005)\"}\n",
    "seed = 42 #@param {type:\"integer\", help:\"Random seed for reproducibility. Set -1 for random.\"}\n",
    "\n",
    "#@markdown ### Advanced Range (Optional)\n",
    "use_frame_range = False #@param {type:\"boolean\"}\n",
    "start_frame = 0 #@param {type:\"integer\"}\n",
    "end_frame = 0 #@param {type:\"integer\"}\n",
    "\n",
    "import subprocess\n",
    "\n",
    "if not os.path.exists(input_path):\n",
    "    print(f\"Error: Input file not found at {input_path}\\nPlease check the path or mount Google Drive.\")\n",
    "else:\n",
    "    print(f\"Processing: {input_path}\")\n",
    "    cmd = [\"python\", \"-u\", \"video_sstv.py\", input_path]\n",
    "    \n",
    "    if not no_video:\n",
    "        cmd.append(output_filename)\n",
    "        \n",
    "    # Basic flags\n",
    "    if preset == \"Custom\":\n",
    "        cmd.extend([\"--width\", str(custom_width), \"--height\", str(custom_height)])\n",
    "    else:\n",
    "        cmd.extend([\"--preset\", preset])\n",
    "        \n",
    "    if bitrate != \"Lossless\":\n",
    "        cmd.extend([\"--bitrate\", bitrate])\n",
    "    cmd.extend([\"--workers\", str(workers)])\n",
    "    \n",
    "    if no_video:\n",
    "        cmd.append(\"--no-video\")\n",
    "        \n",
    "    # Random flags\n",
    "    if random_shift_range > 0:\n",
    "        cmd.extend([\"--random-shift-range\", str(random_shift_range)])\n",
    "    if random_wobble_max > 0:\n",
    "        cmd.extend([\"--random-wobble-max\", str(random_wobble_max)])\n",
    "    if random_skew > 0:\n",
    "        cmd.extend([\"--random-skew\", str(random_skew)])\n",
    "    if seed != -1:\n",
    "        cmd.extend([\"--seed\", str(seed)])\n",
    "        \n",
    "    # Range flags\n",
    "    if use_frame_range:\n",
    "        cmd.extend([\"--start\", str(start_frame)])\n",
    "        if end_frame > 0:\n",
    "             cmd.extend([\"--end\", str(end_frame)])\n",
    "             \n",
    "    print(f\"Executing: {' '.join(cmd)}\")\n",
    "    process = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True, bufsize=1, universal_newlines=True)\n",
    "    for line in iter(process.stdout.readline, ''):\n",
    "        print(line, end='')\n",
    "    process.wait()\n",
    "    if process.returncode != 0:\n",
    "        print(f\"Error: Process failed with exit code {process.returncode}\")\n",
    "    else:\n",
    "        print(\"Processing Complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 5. Download Output\n",
    "from google.colab import files\n",
    "import os\n",
    "\n",
    "if os.path.exists(output_filename):\n",
    "    if \"/content/drive\" in output_filename:\n",
    "        print(f\"File saved to Google Drive: {output_filename}\\n(No download needed)\")\n",
    "    else:\n",
    "        files.download(output_filename)\n",
    "else:\n",
    "    print(f\"File {output_filename} not found. Did the process fail?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
