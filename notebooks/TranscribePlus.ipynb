{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yoSiRFvRQ4Og",
        "outputId": "cb8f89d6-ccd2-44d2-f6f8-d5a6fd8b086e"
      },
      "outputs": [],
      "source": [
        "# @title 1. 环境初始化与恢复\n",
        "import os\n",
        "import sys\n",
        "\n",
        "if not os.path.exists(\"installed_marker\"):\n",
        "    !pip install -q \"torchaudio<2.9\" yt-dlp stable-ts librosa\n",
        "    with open(\"installed_marker\", \"w\") as f:\n",
        "        f.write(\"done\")\n",
        "    os.kill(os.getpid(), 9)\n",
        "\n",
        "import torch\n",
        "import torchaudio\n",
        "import numpy as np\n",
        "import librosa\n",
        "import stable_whisper\n",
        "from google.colab import drive, files\n",
        "from datetime import timedelta\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"Environment ready. Device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uwrfhTRERBfr",
        "outputId": "1eb94bda-3972-4ef8-a049-ce2cc7dba22e"
      },
      "outputs": [],
      "source": [
        "# @title 2. 配置编辑\n",
        "import os\n",
        "import re\n",
        "import subprocess\n",
        "\n",
        "source_type = \"Youtube 链接\" # @param [\"\\u672C\\u5730\\u8DEF\\u5F84\", \"Google Drive\", \"Youtube \\u94FE\\u63A5\"]\n",
        "source_value = \"https://www.youtube.com/watch?v=WCDLyXJgbIo\" # @param {type:\"string\"}\n",
        "\n",
        "audio_file_path = \"\"\n",
        "base_name = \"\"  # 用于后续生成 lrc 的主文件名\n",
        "\n",
        "def sanitize_filename(name):\n",
        "    \"\"\"清理文件名中的非法字符\"\"\"\n",
        "    cleaned = re.sub(r'[\\\\/*?:\"<>|]', \"_\", name).strip()\n",
        "    return cleaned\n",
        "\n",
        "if source_type == \"Youtube 链接\":\n",
        "    print(f\"1. Fetching YouTube title for: {source_value}\")\n",
        "\n",
        "    # 尝试获取视频标题\n",
        "    try:\n",
        "        # 使用 subprocess 获取标题，避免直接 ! 命令的输出解析问题\n",
        "        # 加上 --user-agent 和 client 伪装，防止获取标题时也被 403\n",
        "        cmd = [\n",
        "            \"yt-dlp\", \"--get-title\",\n",
        "            \"--extractor-args\", \"youtube:player_client=android\",\n",
        "            \"--user-agent\", \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\",\n",
        "            source_value\n",
        "        ]\n",
        "        result = subprocess.run(cmd, capture_output=True, text=True, encoding='utf-8')\n",
        "        raw_title = result.stdout.strip()\n",
        "\n",
        "        if not raw_title:\n",
        "            print(\"Warning: Could not fetch title, using default name.\")\n",
        "            raw_title = \"youtube_audio\"\n",
        "\n",
        "        base_name = sanitize_filename(raw_title)\n",
        "        print(f\"   Video Title: {raw_title}\")\n",
        "        print(f\"   Saved Filename: {base_name}.wav\")\n",
        "\n",
        "        # 指定下载文件名为清洗后的标题\n",
        "        audio_file_path = f\"{base_name}.wav\"\n",
        "\n",
        "        print(\"2. Downloading audio...\")\n",
        "        !yt-dlp -x --audio-format wav \\\n",
        "                -o \"{audio_file_path}\" \\\n",
        "                --force-overwrites \\\n",
        "                --extractor-args \"youtube:player_client=android\" \\\n",
        "                --user-agent \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\" \\\n",
        "                \"{source_value}\"\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing YouTube: {e}\")\n",
        "\n",
        "elif source_type == \"Google Drive\":\n",
        "    if not os.path.exists('/content/drive'):\n",
        "        drive.mount('/content/drive')\n",
        "    audio_file_path = source_value\n",
        "    if not os.path.exists(audio_file_path):\n",
        "        raise FileNotFoundError(f\"File not found in Drive: {audio_file_path}\")\n",
        "\n",
        "    filename_with_ext = os.path.basename(audio_file_path)\n",
        "    base_name = os.path.splitext(filename_with_ext)[0]\n",
        "\n",
        "elif source_type == \"本地路径\":\n",
        "    audio_file_path = source_value\n",
        "    if not os.path.exists(audio_file_path):\n",
        "        print(f\"File not found: {audio_file_path}. Please upload it via the files tab.\")\n",
        "        from google.colab import files\n",
        "        uploaded = files.upload()\n",
        "        audio_file_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Rvo_3kKycYG",
        "outputId": "7907de35-bd76-43cd-a9eb-bbe3b5d6ee8a"
      },
      "outputs": [],
      "source": [
        "!pip install -q demucs\n",
        "\n",
        "# @title 2.5 人声分离 (可选：去除 BGM 仅保留人声)\n",
        "import shutil\n",
        "import subprocess\n",
        "\n",
        "if not audio_file_path or not os.path.exists(audio_file_path):\n",
        "    print(\"❌ 未发现有效的音频文件路径，请先执行第 2 步\")\n",
        "else:\n",
        "    # 准备临时文件名，防止 demucs 处理带特殊字符的文件名出错\n",
        "    original_ext = os.path.splitext(audio_file_path)[1]\n",
        "    temp_input = \"/content/temp_sep_input\" + original_ext\n",
        "    shutil.copy(audio_file_path, temp_input)\n",
        "\n",
        "    print(f\"正在提取人声与伴奏 (使用 mdx_extra 模型)...\")\n",
        "    print(\"注意：首次运行会下载模型（约 4GB），请耐心等待。\")\n",
        "\n",
        "    try:\n",
        "        # 运行 demucs 分离人声 (vocals) 和 伴奏 (no_vocals)\n",
        "        subprocess.run(\n",
        "            [\"python3\", \"-m\", \"demucs.separate\",\n",
        "              \"-n\", \"mdx_extra\",\n",
        "              \"--two-stems=vocals\",\n",
        "              \"--out\", \"/content/separated\",\n",
        "              temp_input],\n",
        "            check=True\n",
        "        )\n",
        "\n",
        "        # Demucs 默认输出路径结构: /content/separated/mdx_extra/temp_sep_input/vocals.wav\n",
        "        base_output_path = \"/content/separated/mdx_extra/temp_sep_input\"\n",
        "        vocal_path = os.path.join(base_output_path, \"vocals.wav\")\n",
        "        instr_path = os.path.join(base_output_path, \"no_vocals.wav\")\n",
        "\n",
        "        if os.path.exists(vocal_path):\n",
        "            # 将结果重命名为与原始视频标题相关的名称\n",
        "            final_vocal_name = f\"/content/{base_name}_vocals.wav\"\n",
        "            shutil.move(vocal_path, final_vocal_name)\n",
        "\n",
        "            # 【关键点】更新 audio_file_path，让接下来的第 3 步使用纯人声文件\n",
        "            audio_file_path = final_vocal_name\n",
        "            print(f\"✅ 人声提取成功: {final_vocal_name}\")\n",
        "\n",
        "        if os.path.exists(instr_path):\n",
        "            final_instr_name = f\"/content/{base_name}_instr.wav\"\n",
        "            shutil.move(instr_path, final_instr_name)\n",
        "            print(f\"✅ 伴奏提取成功: {final_instr_name}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ 分离过程出现异常: {e}\")\n",
        "    finally:\n",
        "        # 清理临时文件夹\n",
        "        if os.path.exists(temp_input):\n",
        "            os.remove(temp_input)\n",
        "        if os.path.exists(\"/content/separated\"):\n",
        "            shutil.rmtree(\"/content/separated\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "wUpw9lmRRRaJ",
        "outputId": "c55ed4ff-d462-4f32-cbf9-bce7d2741ac8"
      },
      "outputs": [],
      "source": [
        "# @title 3. 音频转写\n",
        "import os\n",
        "import json\n",
        "import zipfile\n",
        "import torch\n",
        "import stable_whisper\n",
        "from google.colab import files\n",
        "from datetime import timedelta\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 1. 辅助函数定义\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "def sec_to_srt(seconds):\n",
        "    \"\"\"转换秒数为 SRT 格式 00:00:00,000\"\"\"\n",
        "    td = timedelta(seconds=seconds)\n",
        "    total_seconds = int(td.total_seconds())\n",
        "    hours = total_seconds // 3600\n",
        "    minutes = (total_seconds % 3600) // 60\n",
        "    secs = total_seconds % 60\n",
        "    millis = int(td.microseconds / 1000)\n",
        "    return f\"{hours:02d}:{minutes:02d}:{secs:02d},{millis:03d}\"\n",
        "\n",
        "def sec_to_ass(seconds):\n",
        "    \"\"\"转换秒数为 ASS 格式 0:00:00.00\"\"\"\n",
        "    td = timedelta(seconds=seconds)\n",
        "    total_seconds = int(td.total_seconds())\n",
        "    hours = total_seconds // 3600\n",
        "    minutes = (total_seconds % 3600) // 60\n",
        "    secs = total_seconds % 60\n",
        "    # ASS 使用厘秒 (centiseconds)\n",
        "    cs = int(td.microseconds / 10000)\n",
        "    return f\"{hours}:{minutes:02d}:{secs:02d}.{cs:02d}\"\n",
        "\n",
        "def sec_to_lrc(seconds):\n",
        "    \"\"\"转换秒数为 LRC 格式 00:00.00\"\"\"\n",
        "    td = timedelta(seconds=seconds)\n",
        "    minutes = int(td.seconds // 60)\n",
        "    secs = int(td.seconds % 60)\n",
        "    millis = int(td.microseconds / 10000)\n",
        "    return f\"{minutes:02d}:{secs:02d}.{millis:02d}\"\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 2. 模型加载 (常驻内存)\n",
        "# ---------------------------------------------------------\n",
        "if 'vad_model' not in globals() or 'get_speech_timestamps' not in globals():\n",
        "    print(\"正在加载 VAD 模型...\")\n",
        "    vad_model, utils = torch.hub.load(repo_or_dir='snakers4/silero-vad',\n",
        "                                      model='silero_vad',\n",
        "                                      force_reload=False,\n",
        "                                      trust_repo=True)\n",
        "    (get_speech_timestamps, save_audio, read_audio, VADIterator, collect_chunks) = utils\n",
        "else:\n",
        "    print(\"✅ VAD 模型已在内存中。\")\n",
        "\n",
        "if 'whisper_model' not in globals():\n",
        "    print(\"正在加载 Whisper Large-v3 模型...\")\n",
        "    whisper_model = stable_whisper.load_model('large-v3', device=device)\n",
        "else:\n",
        "    print(\"✅ Whisper 模型已在内存中。\")\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 3. 执行识别逻辑 (收集数据)\n",
        "# ---------------------------------------------------------\n",
        "if not os.path.exists(audio_file_path):\n",
        "    raise FileNotFoundError(\"找不到音频文件，请先成功运行第 2 步！\")\n",
        "\n",
        "if not base_name:\n",
        "    base_name = \"transcription_output\"\n",
        "\n",
        "print(f\"\\n正在处理音频: {audio_file_path} ...\")\n",
        "wav = read_audio(audio_file_path)\n",
        "sr = 16000\n",
        "total_duration = len(wav) / sr\n",
        "\n",
        "print(\"Running VAD...\")\n",
        "speech_timestamps = get_speech_timestamps(\n",
        "    wav,\n",
        "    vad_model,\n",
        "    threshold=0.5,\n",
        "    min_speech_duration_ms=250,\n",
        "    min_silence_duration_ms=100\n",
        ")\n",
        "\n",
        "print(f\"识别到 {len(speech_timestamps)} 个语音片段，开始转写并收集数据...\")\n",
        "\n",
        "global_segments = []\n",
        "\n",
        "for i, ts in enumerate(speech_timestamps):\n",
        "    start_sample = ts['start']\n",
        "    end_sample = ts['end'] # VAD 检测到的物理结束点\n",
        "\n",
        "    global_offset_sec = start_sample / sr\n",
        "    vad_absolute_end = end_sample / sr  # 计算 VAD 片段的绝对结束时间\n",
        "\n",
        "    chunk = wav[start_sample:end_sample].numpy()\n",
        "\n",
        "    # 转写\n",
        "    result = whisper_model.transcribe(chunk, language=None)\n",
        "\n",
        "    if not result.text.strip():\n",
        "        continue\n",
        "\n",
        "    # 处理这一句的数据结构\n",
        "    if result.all_words():\n",
        "        first_word_start = result.all_words()[0].start\n",
        "\n",
        "        # 核心修改：\n",
        "        # 句子的开始时间：依然基于第一个词的开始（避免吸入前面的呼吸声）\n",
        "        # 句子的结束时间：强制使用 VAD 的结束时间（Vad_absolute_end），填满句尾空白\n",
        "        sentence_abs_start = global_offset_sec + first_word_start\n",
        "        sentence_abs_end = vad_absolute_end\n",
        "\n",
        "        # 构建单词列表\n",
        "        words_data = []\n",
        "        words_list = result.all_words()\n",
        "\n",
        "        for idx, word in enumerate(words_list):\n",
        "            w_start = global_offset_sec + word.start\n",
        "            w_end = global_offset_sec + word.end\n",
        "\n",
        "            # 细节优化：如果是本句最后一个词，强制将其结束时间延长至句子结束时间\n",
        "            # 这样在 ASS 卡拉OK模式下，最后一个字的变色会持续到句子完全消失\n",
        "            if idx == len(words_list) - 1:\n",
        "                w_end = sentence_abs_end\n",
        "\n",
        "            words_data.append({\n",
        "                \"word\": word.word.strip(),\n",
        "                \"start\": w_start,\n",
        "                \"end\": w_end\n",
        "            })\n",
        "\n",
        "        segment_data = {\n",
        "            \"text\": result.text.strip(),\n",
        "            \"start\": sentence_abs_start,\n",
        "            \"end\": sentence_abs_end,\n",
        "            \"words\": words_data\n",
        "        }\n",
        "        global_segments.append(segment_data)\n",
        "\n",
        "        print(f\"[{int((i+1)/len(speech_timestamps)*100)}%] {result.text.strip()}\")\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 4. 生成五种格式的文件内容\n",
        "# ---------------------------------------------------------\n",
        "print(\"\\n正在生成文件内容...\")\n",
        "\n",
        "# 1. Enhanced LRC\n",
        "lrc_lines = []\n",
        "for seg in global_segments:\n",
        "    lrc_header = f\"[{sec_to_lrc(seg['start'])}]\"\n",
        "    word_seq = \"\".join([f\" <{sec_to_lrc(w['start'])}>{w['word']}\" for w in seg['words']])\n",
        "    lrc_lines.append(f\"{lrc_header}{word_seq}\")\n",
        "content_lrc = \"\\n\".join(lrc_lines)\n",
        "\n",
        "# 2. Sentence-level SRT\n",
        "srt_lines = []\n",
        "for idx, seg in enumerate(global_segments):\n",
        "    srt_lines.append(str(idx + 1))\n",
        "    srt_lines.append(f\"{sec_to_srt(seg['start'])} --> {sec_to_srt(seg['end'])}\")\n",
        "    srt_lines.append(seg['text'])\n",
        "    srt_lines.append(\"\")\n",
        "content_srt = \"\\n\".join(srt_lines)\n",
        "\n",
        "# 3. Word-level SRT\n",
        "word_srt_lines = []\n",
        "w_idx = 1\n",
        "for seg in global_segments:\n",
        "    for w in seg['words']:\n",
        "        word_srt_lines.append(str(w_idx))\n",
        "        word_srt_lines.append(f\"{sec_to_srt(w['start'])} --> {sec_to_srt(w['end'])}\")\n",
        "        word_srt_lines.append(w['word'])\n",
        "        word_srt_lines.append(\"\")\n",
        "        w_idx += 1\n",
        "content_word_srt = \"\\n\".join(word_srt_lines)\n",
        "\n",
        "# 4. Custom JSON\n",
        "json_output = {\n",
        "    \"metadata\": {\n",
        "        \"file\": audio_file_path,\n",
        "        \"duration\": round(total_duration, 2),\n",
        "        \"language\": \"auto\"\n",
        "    },\n",
        "    \"segments\": global_segments\n",
        "}\n",
        "content_json = json.dumps(json_output, indent=2, ensure_ascii=False)\n",
        "\n",
        "# 5. Karaoke ASS\n",
        "ass_header = \"\"\"[Script Info]\n",
        "ScriptType: v4.00+\n",
        "PlayResX: 1920\n",
        "PlayResY: 1080\n",
        "Timer: 100.0000\n",
        "\n",
        "[V4+ Styles]\n",
        "Format: Name, Fontname, Fontsize, PrimaryColour, SecondaryColour, OutlineColour, BackColour, Bold, Italic, Underline, StrikeOut, ScaleX, ScaleY, Spacing, Angle, BorderStyle, Outline, Shadow, Alignment, MarginL, MarginR, MarginV, Encoding\n",
        "Style: Default,Arial,50,&H00FFFFFF,&H000000FF,&H00000000,&H00000000,0,0,0,0,100,100,0,0,1,2,0,2,10,10,10,1\n",
        "\n",
        "[Events]\n",
        "Format: Layer, Start, End, Style, Name, MarginL, MarginR, MarginV, Effect, Text\n",
        "\"\"\"\n",
        "ass_events = []\n",
        "for seg in global_segments:\n",
        "    start_fmt = sec_to_ass(seg['start'])\n",
        "    end_fmt = sec_to_ass(seg['end'])\n",
        "\n",
        "    k_text = \"\"\n",
        "    for i, w in enumerate(seg['words']):\n",
        "        duration = w['end'] - w['start']\n",
        "        k_val = int(duration * 100) # 转换为 ASS 的厘秒单位\n",
        "\n",
        "        prefix = \" \" if i > 0 else \"\"\n",
        "        k_text += f\"{prefix}{{\\\\k{k_val}}}{w['word']}\"\n",
        "\n",
        "    event_line = f\"Dialogue: 0,{start_fmt},{end_fmt},Default,,0,0,0,,{k_text}\"\n",
        "    ass_events.append(event_line)\n",
        "\n",
        "content_ass = ass_header + \"\\n\".join(ass_events)\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 5. 打包与下载\n",
        "# ---------------------------------------------------------\n",
        "zip_filename = f\"{base_name}_subs.zip\"\n",
        "print(f\"\\n正在打包文件到 {zip_filename} ...\")\n",
        "\n",
        "with zipfile.ZipFile(zip_filename, 'w') as zipf:\n",
        "    zipf.writestr(f\"{base_name}.lrc\", content_lrc)\n",
        "    zipf.writestr(f\"{base_name}.srt\", content_srt)\n",
        "    zipf.writestr(f\"{base_name}.word.srt\", content_word_srt)\n",
        "    zipf.writestr(f\"{base_name}.ass\", content_ass)\n",
        "    zipf.writestr(f\"{base_name}.json\", content_json)\n",
        "\n",
        "print(f\"✅ 处理完成，自动下载压缩包。\")\n",
        "files.download(zip_filename)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
