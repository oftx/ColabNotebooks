{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yoSiRFvRQ4Og",
        "outputId": "218c6e55-6fe3-4aa9-e3a0-8a2180e12d71"
      },
      "outputs": [],
      "source": [
        "# @title 1. 环境初始化与恢复\n",
        "import os\n",
        "import sys\n",
        "\n",
        "if not os.path.exists(\"installed_marker\"):\n",
        "    !pip install -q \"torchaudio<2.9\" yt-dlp stable-ts librosa\n",
        "    with open(\"installed_marker\", \"w\") as f:\n",
        "        f.write(\"done\")\n",
        "    os.kill(os.getpid(), 9)\n",
        "\n",
        "import torch\n",
        "import torchaudio\n",
        "import numpy as np\n",
        "import librosa\n",
        "import stable_whisper\n",
        "from google.colab import drive, files\n",
        "from datetime import timedelta\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"Environment ready. Device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uwrfhTRERBfr"
      },
      "outputs": [],
      "source": [
        "# @title 2. 配置编辑\n",
        "import os\n",
        "import re\n",
        "import subprocess\n",
        "\n",
        "source_type = \"Youtube 链接\" # @param [\"\\u672C\\u5730\\u8DEF\\u5F84\", \"Google Drive\", \"Youtube \\u94FE\\u63A5\"]\n",
        "source_value = \"https://www.youtube.com/watch?v=W85F-UmnbF4\" # @param {type:\"string\"}\n",
        "\n",
        "audio_file_path = \"\"\n",
        "base_name = \"\"  # 用于后续生成 lrc 的主文件名\n",
        "\n",
        "def sanitize_filename(name):\n",
        "    \"\"\"清理文件名中的非法字符\"\"\"\n",
        "    cleaned = re.sub(r'[\\\\/*?:\"<>|]', \"_\", name).strip()\n",
        "    return cleaned\n",
        "\n",
        "if source_type == \"Youtube 链接\":\n",
        "    print(f\"1. Fetching YouTube title for: {source_value}\")\n",
        "\n",
        "    # 尝试获取视频标题\n",
        "    try:\n",
        "        # 使用 subprocess 获取标题，避免直接 ! 命令的输出解析问题\n",
        "        # 加上 --user-agent 和 client 伪装，防止获取标题时也被 403\n",
        "        cmd = [\n",
        "            \"yt-dlp\", \"--get-title\",\n",
        "            \"--extractor-args\", \"youtube:player_client=android\",\n",
        "            \"--user-agent\", \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\",\n",
        "            source_value\n",
        "        ]\n",
        "        result = subprocess.run(cmd, capture_output=True, text=True, encoding='utf-8')\n",
        "        raw_title = result.stdout.strip()\n",
        "\n",
        "        if not raw_title:\n",
        "            print(\"Warning: Could not fetch title, using default name.\")\n",
        "            raw_title = \"youtube_audio\"\n",
        "\n",
        "        base_name = sanitize_filename(raw_title)\n",
        "        print(f\"   Video Title: {raw_title}\")\n",
        "        print(f\"   Saved Filename: {base_name}.wav\")\n",
        "\n",
        "        # 指定下载文件名为清洗后的标题\n",
        "        audio_file_path = f\"{base_name}.wav\"\n",
        "\n",
        "        print(\"2. Downloading audio...\")\n",
        "        !yt-dlp -x --audio-format wav \\\n",
        "                -o \"{audio_file_path}\" \\\n",
        "                --force-overwrites \\\n",
        "                --extractor-args \"youtube:player_client=android\" \\\n",
        "                --user-agent \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\" \\\n",
        "                \"{source_value}\"\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing YouTube: {e}\")\n",
        "\n",
        "elif source_type == \"Google Drive\":\n",
        "    if not os.path.exists('/content/drive'):\n",
        "        drive.mount('/content/drive')\n",
        "    audio_file_path = source_value\n",
        "    if not os.path.exists(audio_file_path):\n",
        "        raise FileNotFoundError(f\"File not found in Drive: {audio_file_path}\")\n",
        "\n",
        "    filename_with_ext = os.path.basename(audio_file_path)\n",
        "    base_name = os.path.splitext(filename_with_ext)[0]\n",
        "\n",
        "elif source_type == \"本地路径\":\n",
        "    audio_file_path = source_value\n",
        "    if not os.path.exists(audio_file_path):\n",
        "        print(f\"File not found: {audio_file_path}. Please upload it via the files tab.\")\n",
        "        from google.colab import files\n",
        "        uploaded = files.upload()\n",
        "        audio_file_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "wUpw9lmRRRaJ",
        "outputId": "42d77fa6-ac0f-4285-c3bf-569a8268cf6d"
      },
      "outputs": [],
      "source": [
        "# @title 3. 音频转写\n",
        "import os\n",
        "import json\n",
        "import zipfile\n",
        "import torch\n",
        "import stable_whisper\n",
        "from google.colab import files\n",
        "from datetime import timedelta\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 1. 辅助函数定义\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "def sec_to_srt(seconds):\n",
        "    \"\"\"转换秒数为 SRT 格式 00:00:00,000\"\"\"\n",
        "    td = timedelta(seconds=seconds)\n",
        "    total_seconds = int(td.total_seconds())\n",
        "    hours = total_seconds // 3600\n",
        "    minutes = (total_seconds % 3600) // 60\n",
        "    secs = total_seconds % 60\n",
        "    millis = int(td.microseconds / 1000)\n",
        "    return f\"{hours:02d}:{minutes:02d}:{secs:02d},{millis:03d}\"\n",
        "\n",
        "def sec_to_ass(seconds):\n",
        "    \"\"\"转换秒数为 ASS 格式 0:00:00.00\"\"\"\n",
        "    td = timedelta(seconds=seconds)\n",
        "    total_seconds = int(td.total_seconds())\n",
        "    hours = total_seconds // 3600\n",
        "    minutes = (total_seconds % 3600) // 60\n",
        "    secs = total_seconds % 60\n",
        "    # ASS 使用厘秒 (centiseconds)\n",
        "    cs = int(td.microseconds / 10000)\n",
        "    return f\"{hours}:{minutes:02d}:{secs:02d}.{cs:02d}\"\n",
        "\n",
        "def sec_to_lrc(seconds):\n",
        "    \"\"\"转换秒数为 LRC 格式 00:00.00\"\"\"\n",
        "    td = timedelta(seconds=seconds)\n",
        "    minutes = int(td.seconds // 60)\n",
        "    secs = int(td.seconds % 60)\n",
        "    millis = int(td.microseconds / 10000)\n",
        "    return f\"{minutes:02d}:{secs:02d}.{millis:02d}\"\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 2. 模型加载 (常驻内存)\n",
        "# ---------------------------------------------------------\n",
        "if 'vad_model' not in globals() or 'get_speech_timestamps' not in globals():\n",
        "    print(\"正在加载 VAD 模型...\")\n",
        "    vad_model, utils = torch.hub.load(repo_or_dir='snakers4/silero-vad',\n",
        "                                      model='silero_vad',\n",
        "                                      force_reload=False,\n",
        "                                      trust_repo=True)\n",
        "    (get_speech_timestamps, save_audio, read_audio, VADIterator, collect_chunks) = utils\n",
        "else:\n",
        "    print(\"✅ VAD 模型已在内存中。\")\n",
        "\n",
        "if 'whisper_model' not in globals():\n",
        "    print(\"正在加载 Whisper Large-v3 模型...\")\n",
        "    whisper_model = stable_whisper.load_model('large-v3', device=device)\n",
        "else:\n",
        "    print(\"✅ Whisper 模型已在内存中。\")\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 3. 执行识别逻辑 (收集数据)\n",
        "# ---------------------------------------------------------\n",
        "if not os.path.exists(audio_file_path):\n",
        "    raise FileNotFoundError(\"找不到音频文件，请先成功运行第 2 步！\")\n",
        "\n",
        "if not base_name:\n",
        "    base_name = \"transcription_output\"\n",
        "\n",
        "print(f\"\\n正在处理音频: {audio_file_path} ...\")\n",
        "wav = read_audio(audio_file_path)\n",
        "sr = 16000\n",
        "total_duration = len(wav) / sr\n",
        "\n",
        "print(\"Running VAD...\")\n",
        "speech_timestamps = get_speech_timestamps(\n",
        "    wav,\n",
        "    vad_model,\n",
        "    threshold=0.5,\n",
        "    min_speech_duration_ms=250,\n",
        "    min_silence_duration_ms=100\n",
        ")\n",
        "\n",
        "print(f\"识别到 {len(speech_timestamps)} 个语音片段，开始转写并收集数据...\")\n",
        "\n",
        "# 用于存储所有处理后的数据片段\n",
        "global_segments = []\n",
        "\n",
        "for i, ts in enumerate(speech_timestamps):\n",
        "    start_sample = ts['start']\n",
        "    end_sample = ts['end']\n",
        "    global_offset_sec = start_sample / sr\n",
        "\n",
        "    chunk = wav[start_sample:end_sample].numpy()\n",
        "\n",
        "    # 转写\n",
        "    result = whisper_model.transcribe(chunk, language=None)\n",
        "\n",
        "    if not result.text.strip():\n",
        "        continue\n",
        "\n",
        "    # 处理这一句的数据结构\n",
        "    if result.all_words():\n",
        "        # 获取这一句的绝对开始和结束时间\n",
        "        # 使用第一个词的开始和最后一个词的结束作为句子的边界，这样更紧凑\n",
        "        # 或者使用 global_offset_sec 作为基准，这里我们使用词级边界\n",
        "        first_word_start = result.all_words()[0].start\n",
        "        last_word_end = result.all_words()[-1].end\n",
        "\n",
        "        sentence_abs_start = global_offset_sec + first_word_start\n",
        "        sentence_abs_end = global_offset_sec + last_word_end\n",
        "\n",
        "        # 构建单词列表\n",
        "        words_data = []\n",
        "        for word in result.all_words():\n",
        "            words_data.append({\n",
        "                \"word\": word.word.strip(),\n",
        "                \"start\": global_offset_sec + word.start,\n",
        "                \"end\": global_offset_sec + word.end\n",
        "            })\n",
        "\n",
        "        segment_data = {\n",
        "            \"text\": result.text.strip(),\n",
        "            \"start\": sentence_abs_start,\n",
        "            \"end\": sentence_abs_end,\n",
        "            \"words\": words_data\n",
        "        }\n",
        "        global_segments.append(segment_data)\n",
        "\n",
        "        # 打印进度\n",
        "        print(f\"[{int((i+1)/len(speech_timestamps)*100)}%] {result.text.strip()}\")\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 4. 生成五种格式的文件内容\n",
        "# ---------------------------------------------------------\n",
        "print(\"\\n正在生成文件内容...\")\n",
        "\n",
        "# 1. Enhanced LRC\n",
        "lrc_lines = []\n",
        "for seg in global_segments:\n",
        "    lrc_header = f\"[{sec_to_lrc(seg['start'])}]\"\n",
        "    word_seq = \"\".join([f\" <{sec_to_lrc(w['start'])}>{w['word']}\" for w in seg['words']])\n",
        "    lrc_lines.append(f\"{lrc_header}{word_seq}\")\n",
        "content_lrc = \"\\n\".join(lrc_lines)\n",
        "\n",
        "# 2. Sentence-level SRT\n",
        "srt_lines = []\n",
        "for idx, seg in enumerate(global_segments):\n",
        "    srt_lines.append(str(idx + 1))\n",
        "    srt_lines.append(f\"{sec_to_srt(seg['start'])} --> {sec_to_srt(seg['end'])}\")\n",
        "    srt_lines.append(seg['text'])\n",
        "    srt_lines.append(\"\") # 空行\n",
        "content_srt = \"\\n\".join(srt_lines)\n",
        "\n",
        "# 3. Word-level SRT (每个单词一条字幕)\n",
        "word_srt_lines = []\n",
        "w_idx = 1\n",
        "for seg in global_segments:\n",
        "    for w in seg['words']:\n",
        "        word_srt_lines.append(str(w_idx))\n",
        "        word_srt_lines.append(f\"{sec_to_srt(w['start'])} --> {sec_to_srt(w['end'])}\")\n",
        "        word_srt_lines.append(w['word'])\n",
        "        word_srt_lines.append(\"\")\n",
        "        w_idx += 1\n",
        "content_word_srt = \"\\n\".join(word_srt_lines)\n",
        "\n",
        "# 4. Custom JSON\n",
        "json_output = {\n",
        "    \"metadata\": {\n",
        "        \"file\": audio_file_path,\n",
        "        \"duration\": round(total_duration, 2)\n",
        "    },\n",
        "    \"segments\": global_segments\n",
        "}\n",
        "content_json = json.dumps(json_output, indent=2, ensure_ascii=False)\n",
        "\n",
        "# 5. Karaoke ASS\n",
        "ass_header = \"\"\"[Script Info]\n",
        "ScriptType: v4.00+\n",
        "PlayResX: 1920\n",
        "PlayResY: 1080\n",
        "Timer: 100.0000\n",
        "\n",
        "[V4+ Styles]\n",
        "Format: Name, Fontname, Fontsize, PrimaryColour, SecondaryColour, OutlineColour, BackColour, Bold, Italic, Underline, StrikeOut, ScaleX, ScaleY, Spacing, Angle, BorderStyle, Outline, Shadow, Alignment, MarginL, MarginR, MarginV, Encoding\n",
        "Style: Default,Arial,50,&H00FFFFFF,&H000000FF,&H00000000,&H00000000,0,0,0,0,100,100,0,0,1,2,0,2,10,10,10,1\n",
        "\n",
        "[Events]\n",
        "Format: Layer, Start, End, Style, Name, MarginL, MarginR, MarginV, Effect, Text\n",
        "\"\"\"\n",
        "ass_events = []\n",
        "for seg in global_segments:\n",
        "    start_fmt = sec_to_ass(seg['start'])\n",
        "    end_fmt = sec_to_ass(seg['end'])\n",
        "\n",
        "    # 构建卡拉OK文本 {\\kXX}word\n",
        "    k_text = \"\"\n",
        "    # 为了保证 ASS 时间轴连续，我们需要计算单词之间的相对时间\n",
        "    # ASS 的 \\k 是以 10ms (centiseconds) 为单位\n",
        "    current_k_pos = seg['start']\n",
        "\n",
        "    for i, w in enumerate(seg['words']):\n",
        "        # 计算单词持续时间 (cs)\n",
        "        duration = w['end'] - w['start']\n",
        "        k_val = int(duration * 100)\n",
        "\n",
        "        # 检查是否与上一个词有空隙，如果有空隙，可以选择加到前一个词，或者插入空 \\k\n",
        "        # 这里简单处理：直接拼接，因为 VAD 切分后一句话内通常是连续的\n",
        "        # 但为了更精准，我们在单词前加空格（如果不是第一个词）\n",
        "        prefix = \" \" if i > 0 else \"\"\n",
        "        k_text += f\"{prefix}{{\\\\k{k_val}}}{w['word']}\"\n",
        "\n",
        "    event_line = f\"Dialogue: 0,{start_fmt},{end_fmt},Default,,0,0,0,,{k_text}\"\n",
        "    ass_events.append(event_line)\n",
        "\n",
        "content_ass = ass_header + \"\\n\".join(ass_events)\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 5. 打包与下载\n",
        "# ---------------------------------------------------------\n",
        "zip_filename = f\"{base_name}_subs.zip\"\n",
        "print(f\"\\n正在打包文件到 {zip_filename} ...\")\n",
        "\n",
        "with zipfile.ZipFile(zip_filename, 'w') as zipf:\n",
        "    zipf.writestr(f\"{base_name}.lrc\", content_lrc)\n",
        "    zipf.writestr(f\"{base_name}.srt\", content_srt)\n",
        "    zipf.writestr(f\"{base_name}.word.srt\", content_word_srt)\n",
        "    zipf.writestr(f\"{base_name}.ass\", content_ass)\n",
        "    zipf.writestr(f\"{base_name}.json\", content_json)\n",
        "\n",
        "print(f\"✅ 处理完成，自动下载压缩包。\")\n",
        "files.download(zip_filename)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
